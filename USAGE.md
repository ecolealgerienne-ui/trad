# üöÄ Guide d'Utilisation - Entra√Ænement CNN-LSTM

## Arguments en Ligne de Commande

Le script `train.py` accepte maintenant des arguments CLI pour personnaliser l'entra√Ænement sans modifier `constants.py`.

### Utilisation de Base

```bash
# Entra√Ænement avec param√®tres par d√©faut
python src/train.py

# Afficher l'aide
python src/train.py --help
```

---

## üìä Hyperparam√®tres

### Batch Size

```bash
# Batch size par d√©faut (32)
python src/train.py

# Batch size personnalis√©
python src/train.py --batch-size 64
python src/train.py --batch-size 16  # Pour GPU avec moins de m√©moire
```

**Recommandations** :
- **CPU** : 16-32
- **GPU (4GB)** : 32-64
- **GPU (8GB+)** : 64-128

### Learning Rate

```bash
# Learning rate par d√©faut (0.001)
python src/train.py

# Learning rate personnalis√©
python src/train.py --lr 0.0001  # Plus conservateur
python src/train.py --lr 0.01    # Plus agressif
```

**Recommandations** :
- Commencer avec **0.001**
- Si loss oscille : r√©duire √† **0.0001**
- Si convergence trop lente : augmenter √† **0.005**

### Nombre d'√âpoques

```bash
# Nombre d'√©poques par d√©faut (100)
python src/train.py

# Nombre d'√©poques personnalis√©
python src/train.py --epochs 50   # Entra√Ænement court
python src/train.py --epochs 200  # Entra√Ænement long
```

### Early Stopping Patience

```bash
# Patience par d√©faut (10)
python src/train.py

# Patience personnalis√©e
python src/train.py --patience 5   # Arr√™te plus rapidement
python src/train.py --patience 20  # Plus de tol√©rance
```

---

## üî¨ Type de Filtre pour Labels

```bash
# Filtre par d√©faut (Decycler)
python src/train.py

# Forcer filtre Decycler
python src/train.py --filter decycler

# Utiliser filtre Kalman (meilleure qualit√©)
python src/train.py --filter kalman
```

**Comparaison des filtres** :
- **Decycler** : Filtre de Ehlers, rapide, ~67% accuracy
- **Kalman** : Kalman smoothing, meilleure qualit√©, ~85% accuracy

**Recommandation** : Utiliser `--filter kalman` pour de meilleurs r√©sultats.

---

## üíª Device (CPU/GPU)

```bash
# Auto-d√©tection (par d√©faut)
python src/train.py

# Forcer CPU
python src/train.py --device cpu

# Forcer GPU
python src/train.py --device cuda
```

---

## üíæ Chemins de Sauvegarde

```bash
# Chemin par d√©faut (models/best_model.pth)
python src/train.py

# Chemin personnalis√©
python src/train.py --save-path models/experiment_1.pth
python src/train.py --save-path models/cnn_lstm_v2.pth
```

---

## üé≤ Random Seed

```bash
# Seed par d√©faut (42)
python src/train.py

# Seed personnalis√© (pour reproductibilit√©)
python src/train.py --seed 123
```

---

## üî• Exemples Pratiques

### Test Rapide (CPU, petit batch)

```bash
python src/train.py \
    --batch-size 16 \
    --epochs 10 \
    --device cpu
```

### Entra√Ænement Standard (GPU)

```bash
python src/train.py \
    --batch-size 64 \
    --lr 0.001 \
    --epochs 100 \
    --patience 10 \
    --filter kalman
```

### Entra√Ænement Long (GPU puissant)

```bash
python src/train.py \
    --batch-size 128 \
    --lr 0.001 \
    --epochs 200 \
    --patience 15 \
    --filter kalman
```

### Fine-tuning avec Learning Rate Bas

```bash
python src/train.py \
    --batch-size 32 \
    --lr 0.0001 \
    --epochs 50 \
    --patience 20
```

### Exp√©rimentation (sauvegarder dans un fichier diff√©rent)

```bash
python src/train.py \
    --batch-size 64 \
    --lr 0.005 \
    --epochs 100 \
    --save-path models/experiment_lr005.pth \
    --seed 999
```

---

## üìà Monitoring Pendant l'Entra√Ænement

### GPU

Dans un terminal s√©par√© :

```bash
watch -n 2 nvidia-smi
```

### Logs

Le script affiche en temps r√©el :
- Train Loss / Accuracy / F1
- Val Loss / Accuracy / F1
- Meilleur mod√®le sauvegard√©

---

## ‚ö†Ô∏è Troubleshooting

### Out of Memory (GPU)

```bash
# R√©duire batch size
python src/train.py --batch-size 16

# Ou forcer CPU
python src/train.py --device cpu
```

### Convergence Lente

```bash
# Augmenter learning rate
python src/train.py --lr 0.005

# Ou augmenter nombre d'√©poques
python src/train.py --epochs 200
```

### Loss Oscille

```bash
# R√©duire learning rate
python src/train.py --lr 0.0001

# Augmenter batch size (plus stable)
python src/train.py --batch-size 128
```

### Overfitting (Val Loss monte)

```bash
# R√©duire patience (arr√™te plus t√¥t)
python src/train.py --patience 5

# Ou augmenter donn√©es (modifier constants.py)
```

---

## üìö Valeurs par D√©faut

D√©finies dans `src/constants.py` :

```python
BATCH_SIZE = 32
LEARNING_RATE = 0.001
NUM_EPOCHS = 100
EARLY_STOPPING_PATIENCE = 10
RANDOM_SEED = 42
```

---

## ‚úÖ V√©rification Post-Entra√Ænement

```bash
# √âvaluer le mod√®le
python src/evaluate.py

# V√©rifier les fichiers g√©n√©r√©s
ls -lh models/
ls -lh results/

# Visualiser l'historique
cat models/training_history.json
```

---

**Cr√©√© le** : 2026-01-01
**Version** : 1.0
