# üéØ Guide Complet - Stacking / Ensemble Learning

**Date**: 2026-01-06
**Objectif**: Combiner les 3 mod√®les experts (MACD, RSI, CCI) pour am√©liorer la pr√©diction Direction

---

## üí° CONCEPT - R√©soudre le Proxy Learning Failure

### Probl√®me Actuel

| M√©trique | Valeur | Probl√®me |
|----------|--------|----------|
| **Accuracy Direction** | 92% | ‚úÖ Excellent |
| **Win Rate Trading** | 14% | ‚ùå Catastrophique |
| **Cause** | Proxy Learning Failure | IA ne pr√©dit pas ce que pr√©dit l'Oracle |

### Hypoth√®se Stacking

> "Le Kalman original est rentable (Oracle 65-70% Win Rate). Si le Stacking am√©liore l'Accuracy de 92% ‚Üí 95-96%, on devrait **coller mieux au Kalman** et retrouver naturellement la rentabilit√©."

**Approche**: Ensemble Learning pur - Combiner les 3 experts pour retrouver la V√©rit√© (Kalman)

---

## üèóÔ∏è ARCHITECTURE

### Niveau 1: Les 3 Mod√®les de Base

| Mod√®le | R√¥le | Caract√©ristique |
|--------|------|-----------------|
| **MACD** | Tendance lourde | Stable mais en retard dans les virages |
| **RSI** | Vitesse pure | R√©actif mais nerveux |
| **CCI** | Volatilit√© | D√©tecte les extremes |

**Chacun pr√©dit**: Direction (UP/DOWN) + Force (STRONG/WEAK)

---

### Niveau 2: Meta-Mod√®le

**Inputs (X_meta)**:
```
X_meta = [
    p_macd_dir,    # Proba Direction MACD (0-1)
    p_macd_force,  # Proba Force MACD (0-1)
    p_rsi_dir,     # Proba Direction RSI (0-1)
    p_rsi_force,   # Proba Force RSI (0-1)
    p_cci_dir,     # Proba Direction CCI (0-1)
    p_cci_force,   # Proba Force CCI (0-1)
]
Shape: (n, 6)
```

**Cible (Y_meta)**:
```
Y_meta = kalman_dir  # Label Direction Original (0 ou 1)
Shape: (n, 1)
```

**Objectif**: Apprendre √† combiner les 6 signaux pour retrouver le Kalman original.

---

### R√®gles Automatiques Apprises

Le meta-mod√®le apprendra automatiquement des patterns comme:

```python
Si RSI_dir change ET MACD_dir stable:
    ‚Üí √âcouter RSI (virage anticip√©)

Si MACD_dir + RSI_dir + CCI_dir tous d'accord:
    ‚Üí Confiance maximale (suivre le consensus)

Si CCI_force WEAK ET MACD_dir change:
    ‚Üí Ignorer MACD (faux signal en volatilit√© faible)

Si RSI_force STRONG ET MACD_force WEAK:
    ‚Üí Retournement imminent (√©couter RSI)
```

---

## üöÄ WORKFLOW COMPLET

### ‚úÖ √âtape 0: Pr√©requis

**V√©rifier que vous avez**:
1. Les 3 datasets dual_binary_kalman.npz
2. Les 3 mod√®les entra√Æn√©s (.pth)

**Si manquants**, ex√©cuter:

```bash
# 1. G√©n√©rer datasets
python src/prepare_data_purified_dual_binary.py --assets BTC ETH BNB ADA LTC

# 2. Entra√Æner les 3 mod√®les
python src/train.py --data data/prepared/dataset_btc_eth_bnb_ada_ltc_macd_dual_binary_kalman.npz --epochs 50
python src/train.py --data data/prepared/dataset_btc_eth_bnb_ada_ltc_rsi_dual_binary_kalman.npz --epochs 50
python src/train.py --data data/prepared/dataset_btc_eth_bnb_ada_ltc_cci_dual_binary_kalman.npz --epochs 50
```

---

### ‚úÖ √âtape 1: G√©n√©rer les M√©ta-Features

**Script**: `src/generate_meta_features.py`

```bash
python src/generate_meta_features.py --assets BTC ETH BNB ADA LTC
```

**Ce que fait ce script**:
1. Charge les 3 mod√®les entra√Æn√©s (.pth)
2. Charge les 3 datasets correspondants
3. G√©n√®re les pr√©dictions (probabilit√©s) pour Train/Val/Test
4. Sauvegarde les m√©ta-features

**Outputs**:
```
data/meta/
  ‚îú‚îÄ‚îÄ meta_features_train.npz  # X_meta: (n, 6), Y_meta: (n, 1)
  ‚îú‚îÄ‚îÄ meta_features_val.npz
  ‚îî‚îÄ‚îÄ meta_features_test.npz
```

**Dur√©e**: ~2-3 min (g√©n√©ration des pr√©dictions)

---

### ‚úÖ √âtape 2: Entra√Æner le Meta-Mod√®le

**Script**: `src/train_stacking.py`

**3 mod√®les disponibles** (tester du plus simple au plus complexe):

#### 2.1 Logistic Regression (Baseline)

```bash
python src/train_stacking.py --model logistic
```

**Avantages**:
- ‚úÖ Rapide (~10 secondes)
- ‚úÖ Interpr√©table (poids des features)
- ‚úÖ Baseline de r√©f√©rence

**Attendu**: Si lin√©aire suffit, devrait atteindre 94-95%

---

#### 2.2 Random Forest

```bash
python src/train_stacking.py --model rf
```

**Avantages**:
- ‚úÖ Capture interactions non-lin√©aires
- ‚úÖ Robuste
- ‚úÖ Feature importance

**Attendu**: Si non-lin√©aire, devrait atteindre 95-96%

---

#### 2.3 MLP (Neural Network)

```bash
python src/train_stacking.py --model mlp --device cuda
```

**Avantages**:
- ‚úÖ Capture patterns tr√®s non-lin√©aires
- ‚úÖ Flexible

**Attendu**: Si tr√®s complexe, devrait atteindre 96%+

---

### ‚úÖ √âtape 3: √âvaluer les R√©sultats

**Comparer les 3 mod√®les**:

| Mod√®le | Train Acc | Val Acc | Test Acc | Interpr√©table | Temps |
|--------|-----------|---------|----------|---------------|-------|
| Logistic | ? | ? | ? | ‚úÖ Oui | ~10s |
| Random Forest | ? | ? | ? | ‚ö†Ô∏è Moyen | ~30s |
| MLP | ? | ? | ? | ‚ùå Non | ~2 min |

**Choisir le mod√®le** avec le meilleur Test Acc sans overfit (gap Train/Test < 5%).

---

## üìä GAIN ATTENDU

### Sc√©nario Optimiste

| M√©trique | Actuel | Attendu | Gain |
|----------|--------|---------|------|
| **Accuracy Direction** | 92% | **95-96%** | +3-4% |
| **Corr√©lation avec Kalman** | ~0.75 | **~0.90** | +20% |
| **Win Rate Trading** | 14% | **55-65%** | **+41-51%** üéØ |

**Justification**:
- Si on colle mieux au Kalman (95-96% Accuracy)
- Et que le Kalman est rentable (65-70% Win Rate Oracle)
- Alors l'IA devrait retrouver 80-90% de cette rentabilit√©

---

## üéØ COMPARAISON AVEC PROFITABILITY RELABELING

| Approche | Objectif | Cible | R√©sultat Attendu |
|----------|----------|-------|------------------|
| **Profitability** | Nettoyer Force | Labels relabel√©s | Oracle +6-8% Win Rate |
| **Stacking** | Combiner experts | **Kalman Direction** | **IA +41-51% Win Rate** |

**Stacking = Solution au Proxy Learning Failure** üéØ

---

## üîç ANALYSE DES R√âSULTATS

### Si Logistic Regression Suffit (94-95%)

**Interpr√©tation**: La combinaison optimale est **lin√©aire**.

**Analyse des poids**:
```python
Poids positifs √©lev√©s ‚Üí Feature importante pour UP
Poids n√©gatifs √©lev√©s ‚Üí Feature importante pour DOWN

Exemple:
  MACD_dir:   +0.45  (fort signal UP si MACD pr√©dit UP)
  RSI_dir:    +0.30  (signal UP mod√©r√©)
  RSI_force:  -0.20  (si Force faible, ignore RSI)
```

**R√®gles apprises**: Pond√©ration simple des 3 experts.

---

### Si Random Forest Meilleur (95-96%)

**Interpr√©tation**: Interactions **non-lin√©aires** importantes.

**Analyse Feature Importance**:
```python
Feature Importance:
  RSI_dir:     0.25  (le plus important pour virages)
  MACD_dir:    0.20  (tendance principale)
  CCI_force:   0.15  (d√©tection extremes)
  ...
```

**R√®gles apprises**: D√©cisions en arbre (ex: SI RSI_dir > 0.6 ET MACD_force < 0.3 ALORS...)

---

### Si MLP N√©cessaire (96%+)

**Interpr√©tation**: Patterns **tr√®s complexes** n√©cessaires.

**Hypoth√®se**: Le mod√®le apprend des interactions d'ordre sup√©rieur (ex: RSI√óMACD√óCCI).

---

## üö® CRIT√àRES DE SUCC√àS

| Crit√®re | Objectif | Verdict |
|---------|----------|---------|
| **Test Accuracy** | ‚â• 95% | ‚úÖ / ‚ùå |
| **Gap Train/Test** | < 5% | ‚úÖ / ‚ùå |
| **Am√©lioration vs Baseline** | +3-4% | ‚úÖ / ‚ùå |

**Si 3/3 ‚úÖ** ‚Üí Stacking valid√©, tester en backtest

---

## üìã TROUBLESHOOTING

### Probl√®me: Test Acc < 94%

**Causes possibles**:
- Les 3 mod√®les de base sont trop similaires (redondants)
- Pas assez de diversit√© dans les pr√©dictions

**Solutions**:
- V√©rifier que les 3 mod√®les ont des performances diff√©rentes
- Ajouter des features (volatilit√©, volume)

---

### Probl√®me: Overfit (Train 98%, Test 93%)

**Causes**: Meta-mod√®le trop complexe (MLP)

**Solutions**:
- Revenir √† Logistic ou Random Forest
- Augmenter dropout MLP
- R√©duire hidden size MLP

---

### Probl√®me: Am√©lioration Faible (+1-2%)

**Causes**: Les 3 mod√®les font les m√™mes erreurs

**Solutions**:
- V√©rifier la diversit√© des mod√®les
- Entra√Æner les mod√®les de base avec des architectures diff√©rentes

---

## üéì LITT√âRATURE - Ensemble Learning

**Stacking** (Wolpert, 1992):
> "Combine multiple models to achieve better performance than any single model."

**Avantages**:
- R√©duit biais et variance
- Exploite la diversit√© des mod√®les
- Robuste aux erreurs individuelles

**Exemples c√©l√®bres**:
- Netflix Prize (2009): √âquipe gagnante utilisait Stacking
- Kaggle: 80% des solutions top utilisent Ensemble Learning

---

## üèÅ PROCHAINES √âTAPES (Si Succ√®s)

### √âtape 4: Backtest Complet

Comparer Win Rate:
- MACD seul: 14%
- RSI seul: 12%
- CCI seul: 13%
- **Stacking**: 55-65% ? üéØ

---

### √âtape 5: Combiner avec Profitability Relabeling

**Approche hybride**:
1. **Stacking** pour am√©liorer Direction (92% ‚Üí 95%)
2. **Profitability Relabeling** pour nettoyer Force

**Gain total attendu**: Win Rate 14% ‚Üí **65-70%** (Oracle-like) üèÜ

---

## ‚úÖ CHECKLIST D'EX√âCUTION

- [ ] Datasets g√©n√©r√©s (3 fichiers .npz)
- [ ] Mod√®les entra√Æn√©s (3 fichiers .pth)
- [ ] M√©ta-features g√©n√©r√©es (generate_meta_features.py)
- [ ] Meta-mod√®le entra√Æn√© (train_stacking.py)
- [ ] Test Accuracy ‚â• 95%
- [ ] Backtest Win Rate > 50%

---

**C'est la m√©thode la plus pure pour v√©rifier l'hypoth√®se: Est-ce que l'union fait la force pour retrouver le Kalman ?** üöÄ

