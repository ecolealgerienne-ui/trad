"""
Script d'√©valuation du mod√®le CNN-LSTM sur le test set.

√âvalue le meilleur mod√®le sauvegard√© et calcule les m√©triques d√©taill√©es.
"""

import numpy as np
import torch
from torch.utils.data import DataLoader
from pathlib import Path
import logging
import json
import argparse
from typing import Dict

logger = logging.getLogger(__name__)

# Import modules locaux
from constants import (
    BATCH_SIZE,
    BEST_MODEL_PATH,
    RESULTS_DIR
)
from model import create_model, compute_metrics
from train import IndicatorDataset
from prepare_data import load_prepared_data, filter_by_assets
from data_utils import normalize_labels_for_single_output
from utils import log_dataset_metadata


def evaluate_model(
    model: torch.nn.Module,
    dataloader: DataLoader,
    loss_fn: torch.nn.Module,
    device: str,
    indicator_names: list = None
) -> Dict[str, float]:
    """
    √âvalue le mod√®le sur un dataset.

    Args:
        model: Mod√®le
        dataloader: DataLoader
        loss_fn: Loss function
        device: Device
        indicator_names: Noms des outputs (ex: ['Direction', 'Force'] pour dual-binary)

    Returns:
        Dictionnaire avec toutes les m√©triques
    """
    model.eval()

    total_loss = 0.0
    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for batch in dataloader:
            # Unpacking flexible: (X, Y) ou (X, Y, T)
            if len(batch) == 3:
                X_batch, Y_batch, T_batch = batch
                # T_batch non utilis√© en √©valuation (seulement pour training loss)
            else:
                X_batch, Y_batch = batch

            # D√©placer sur device
            X_batch = X_batch.to(device)
            Y_batch = Y_batch.to(device)

            # Forward (retourne logits ou probabilit√©s selon use_bce_with_logits)
            model_outputs = model(X_batch)

            # Loss (applique sigmoid si BCEWithLogitsLoss, sinon attend probabilit√©s)
            loss = loss_fn(model_outputs, Y_batch)

            # Obtenir probabilit√©s pour m√©triques (g√®re sigmoid conditionnellement)
            outputs = model.predict_proba(X_batch)

            # Accumuler
            total_loss += loss.item() * X_batch.size(0)
            all_predictions.append(outputs.cpu())
            all_targets.append(Y_batch.cpu())

    # Moyennes
    avg_loss = total_loss / len(dataloader.dataset)

    # M√©triques
    all_predictions = torch.cat(all_predictions, dim=0)
    all_targets = torch.cat(all_targets, dim=0)
    metrics = compute_metrics(all_predictions, all_targets, indicator_names=indicator_names)
    metrics['loss'] = avg_loss

    return metrics


def print_metrics_table(metrics: Dict[str, float], indicator_names: list = None):
    """
    Affiche un tableau format√© des m√©triques.

    Args:
        metrics: Dictionnaire de m√©triques
        indicator_names: Liste des noms d'indicateurs (auto-d√©tect√© si None)
    """
    logger.info("\n" + "="*80)
    logger.info("M√âTRIQUES PAR INDICATEUR")
    logger.info("="*80)

    # Header
    logger.info(f"{'Indicateur':<12} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1':<10}")
    logger.info("-"*80)

    # D√©terminer les indicateurs √† afficher
    if indicator_names is None:
        # D√©tecter depuis les m√©triques disponibles
        if 'RSI_accuracy' in metrics:
            indicator_names = ['RSI', 'CCI', 'MACD']
        elif 'INDICATOR_accuracy' in metrics:
            indicator_names = ['INDICATOR']
        else:
            indicator_names = []

    # Lignes par indicateur
    for name in indicator_names:
        acc = metrics.get(f'{name}_accuracy', 0.0)
        prec = metrics.get(f'{name}_precision', 0.0)
        rec = metrics.get(f'{name}_recall', 0.0)
        f1 = metrics.get(f'{name}_f1', 0.0)

        # Ne pas afficher si pas de donn√©es
        if acc == 0.0 and prec == 0.0 and rec == 0.0 and f1 == 0.0:
            continue

        logger.info(f"{name:<12} {acc:<10.3f} {prec:<10.3f} {rec:<10.3f} {f1:<10.3f}")

    # Moyennes (seulement si plus d'un indicateur)
    if len(indicator_names) > 1:
        logger.info("-"*80)
        avg_acc = metrics.get('avg_accuracy', 0.0)
        avg_prec = metrics.get('avg_precision', 0.0)
        avg_rec = metrics.get('avg_recall', 0.0)
        avg_f1 = metrics.get('avg_f1', 0.0)

        logger.info(f"{'MOYENNE':<12} {avg_acc:<10.3f} {avg_prec:<10.3f} {avg_rec:<10.3f} {avg_f1:<10.3f}")

    # Vote majoritaire
    if 'vote_accuracy' in metrics:
        logger.info("="*80)
        logger.info("VOTE MAJORITAIRE (Moyenne des 3 pr√©dictions)")
        logger.info("="*80)

        vote_acc = metrics['vote_accuracy']
        vote_prec = metrics['vote_precision']
        vote_rec = metrics['vote_recall']
        vote_f1 = metrics['vote_f1']

        logger.info(f"{'VOTE':<12} {vote_acc:<10.3f} {vote_prec:<10.3f} {vote_rec:<10.3f} {vote_f1:<10.3f}")


def parse_args():
    """Parse les arguments CLI."""
    parser = argparse.ArgumentParser(
        description='√âvaluation du mod√®le CNN-LSTM sur le test set',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument('--data', '-d', type=str, required=True,
                        help='Chemin vers les donn√©es pr√©par√©es (.npz). '
                             'IMPORTANT: Doit √™tre le m√™me dataset utilis√© pour l\'entra√Ænement!')

    parser.add_argument('--model', '-m', type=str, default=None,
                        help='Chemin vers le mod√®le (.pth). Si non sp√©cifi√©, utilise le chemin par d√©faut.')

    parser.add_argument('--indicator', '-i', type=str, default='all',
                        choices=['all', 'rsi', 'cci', 'macd', 'close', 'macd40', 'macd26', 'macd13'],
                        help='Indicateur √† √©valuer (all=multi-output, autres=single-output)')

    parser.add_argument('--filter', '-f', type=str, default=None,
                        help='Nom du filtre utilis√© (ex: octave20, kalman). '
                             'Utilis√© pour trouver le mod√®le automatiquement.')

    # Assets filtering
    parser.add_argument('--assets', type=str, nargs='+', default=None,
                        help='Assets √† utiliser (ex: --assets BTC ETH). '
                             'Si non sp√©cifi√©, utilise tous les assets du dataset.')

    return parser.parse_args()


# Mapping indicateur -> index (pour datasets multi-output)
# Pour les single-output (close, macd40, etc.), l'index est None
INDICATOR_INDEX = {
    'rsi': 0, 'cci': 1, 'macd': 2,
    'close': None, 'macd40': None, 'macd26': None, 'macd13': None
}
INDICATOR_NAMES = {
    'rsi': 'RSI', 'cci': 'CCI', 'macd': 'MACD',
    'close': 'CLOSE', 'macd40': 'MACD40', 'macd26': 'MACD26', 'macd13': 'MACD13'
}


def main():
    """Pipeline complet d'√©valuation."""
    # Parser arguments
    args = parse_args()

    # Configurer logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s - %(message)s'
    )

    logger.info("="*80)
    logger.info("√âVALUATION DU MOD√àLE CNN-LSTM")
    logger.info("="*80)

    # NOTE: Mode sera d√©termin√© APR√àS d√©tection auto de l'indicateur depuis le nom du fichier

    # Device
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    logger.info(f"\nDevice: {device}")

    # =========================================================================
    # CHARGEMENT PR√âLIMINAIRE DES M√âTADONN√âES (pour d√©tection filtre)
    # =========================================================================
    filter_type_metadata = None
    if args.data and not args.model:
        # Charger uniquement les m√©tadonn√©es (rapide)
        try:
            preliminary_data = load_prepared_data(args.data)
            preliminary_metadata = preliminary_data.get('metadata', {})
            if preliminary_metadata and 'filter_type' in preliminary_metadata:
                filter_type_metadata = preliminary_metadata['filter_type']
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible de charger les m√©tadonn√©es: {e}")

    # =========================================================================
    # AUTO-D√âTECTION DU CHEMIN DU MOD√àLE (logique identique √† train.py)
    # =========================================================================
    if args.model:
        model_path = args.model
        # Si mod√®le sp√©cifi√© manuellement, d√©terminer mode depuis args.indicator
        single_indicator = args.indicator != 'all'
        if single_indicator:
            indicator_idx = INDICATOR_INDEX[args.indicator]
            indicator_name = INDICATOR_NAMES[args.indicator]
            logger.info(f"\nüéØ Mode SINGLE-OUTPUT: {indicator_name}")
        else:
            indicator_idx = None
            indicator_name = None
            logger.info(f"\nüéØ Mode MULTI-OUTPUT: RSI, CCI, MACD")
    else:
        # D√©tecter l'indicateur et le filtre depuis le nom du fichier dataset
        detected_indicator = None
        detected_filter = None

        if args.data:
            data_name = Path(args.data).stem.lower()

            # D√©tecter indicateur (ex: dataset_..._rsi_dual_binary_kalman.npz ‚Üí 'rsi')
            for ind in ['rsi', 'cci', 'macd', 'close']:
                if f'_{ind}_' in data_name or data_name.endswith(f'_{ind}'):
                    detected_indicator = ind
                    break

            # D√©tecter filtre (fallback si pas dans metadata)
            for filt in ['kalman', 'octave20', 'octave', 'decycler']:
                if filt in data_name:
                    detected_filter = filt
                    break

        # Priorit√©: CLI > filename
        if args.indicator and args.indicator != 'all':
            detected_indicator = args.indicator

        # Priorit√© pour le filtre: metadata > CLI argument > filename
        if filter_type_metadata:
            detected_filter = filter_type_metadata
        elif args.filter:
            detected_filter = args.filter

        # =========================================================================
        # D√âTERMINER MODE (single vs multi) APR√àS d√©tection indicateur
        # =========================================================================
        # Si indicateur d√©tect√© (filename) OU CLI != 'all' ‚Üí SINGLE-OUTPUT
        single_indicator = detected_indicator is not None or args.indicator != 'all'

        if single_indicator:
            if detected_indicator:
                indicator_idx = INDICATOR_INDEX.get(detected_indicator)
                indicator_name = INDICATOR_NAMES.get(detected_indicator, detected_indicator.upper())
            else:
                indicator_idx = INDICATOR_INDEX[args.indicator]
                indicator_name = INDICATOR_NAMES[args.indicator]
            num_outputs = 1
            logger.info(f"\nüéØ Mode SINGLE-OUTPUT: {indicator_name}")
            logger.info(f"   Indicateur d√©tect√©: {detected_indicator or args.indicator}")
        else:
            indicator_idx = None
            indicator_name = None
            num_outputs = 3
            logger.info(f"\nüéØ Mode MULTI-OUTPUT: RSI, CCI, MACD")

        # Construire le nom du mod√®le
        suffix_parts = []
        if detected_indicator:
            suffix_parts.append(detected_indicator)
        if detected_filter:
            suffix_parts.append(detected_filter)

        # D√©tecter si c'est dual-binary depuis le nom du fichier
        data_name_lower = Path(args.data).stem.lower()
        if args.data and 'dual_binary' in data_name_lower:
            suffix_parts.append('dual_binary')

        # Phase 2.11: D√©tecter si c'est un dataset avec transitions (_wt)
        if args.data and '_wt' in data_name_lower:
            suffix_parts.append('wt')

        if suffix_parts:
            suffix = '_'.join(suffix_parts)
            model_path = BEST_MODEL_PATH.replace('.pth', f'_{suffix}.pth')
        else:
            model_path = BEST_MODEL_PATH

        logger.info(f"\nüîç D√©tection auto du mod√®le:")
        logger.info(f"  Indicateur d√©tect√©: {detected_indicator or 'aucun'}")
        logger.info(f"  Filtre d√©tect√©: {detected_filter or 'aucun'}")
        if filter_type_metadata:
            logger.info(f"  Source filtre: m√©tadonn√©es")
        logger.info(f"  Chemin mod√®le: {model_path}")

    # V√©rifier que le mod√®le existe
    if not Path(model_path).exists():
        logger.error(f"‚ùå Mod√®le non trouv√©: {model_path}")
        if single_indicator:
            filter_hint = f" --filter {args.filter}" if args.filter else ""
            logger.error(f"   Entra√Æner d'abord: python src/train.py --data {args.data} --indicator {args.indicator}{filter_hint}")
        else:
            logger.error(f"   Entra√Æner d'abord le mod√®le: python src/train.py --data {args.data}")
        return

    # =========================================================================
    # 1. CHARGER LES DONN√âES
    # =========================================================================
    # Charger donn√©es pr√©par√©es (m√™me dataset que l'entra√Ænement)
    logger.info(f"\n1. Chargement des donn√©es pr√©par√©es: {args.data}")
    prepared = load_prepared_data(args.data)

    # Unpacking flexible: (X, Y) ou (X, Y, T)
    if len(prepared['test']) == 3:
        X_test, Y_test, T_test = prepared['test']
        has_transitions = True
        logger.info("  ‚úÖ Dataset avec transitions d√©tect√© (Phase 2.11)")
    else:
        X_test, Y_test = prepared['test']
        T_test = None
        has_transitions = False

    metadata = prepared['metadata']
    log_dataset_metadata(metadata, logger)

    # FILTRAGE PAR ASSETS (optionnel)
    if args.assets:
        logger.info(f"\nüîç Filtrage des assets...")

        # Charger OHLCV depuis le fichier .npz pour le filtrage
        data_npz = np.load(args.data, allow_pickle=True)

        # Filtrer test
        X_test, Y_test, T_test, _ = filter_by_assets(
            X_test, Y_test, T_test, data_npz['OHLCV_test'],
            args.assets, metadata
        )

        logger.info(f"  ‚úÖ Filtrage termin√© pour {len(args.assets)} asset(s)")

    # Filtrer les labels si mode single-output
    if single_indicator:
        Y_test = normalize_labels_for_single_output(Y_test, indicator_idx, indicator_name)

    logger.info(f"  Test: X={X_test.shape}, Y={Y_test.shape}")
    if has_transitions:
        logger.info(f"        T={T_test.shape} (transitions: {T_test.mean()*100:.1f}%)")

    # =========================================================================
    # 3. CR√âER DATALOADER
    # =========================================================================
    logger.info("\n3. Cr√©ation du DataLoader...")

    test_dataset = IndicatorDataset(X_test, Y_test, T_test)
    test_loader = DataLoader(
        test_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0
    )

    logger.info(f"  Test batches: {len(test_loader)}")

    # =========================================================================
    # 4. CHARGER LE MOD√àLE ET AUTO-D√âTECTER L'ARCHITECTURE
    # =========================================================================
    logger.info(f"\n4. Chargement du mod√®le depuis {model_path}...")

    # Charger checkpoint pour r√©cup√©rer la config du mod√®le
    checkpoint = torch.load(model_path, map_location=device)

    # R√©cup√©rer config du mod√®le (ou utiliser d√©fauts si ancien checkpoint)
    model_config = checkpoint.get('model_config', {})

    # =========================================================================
    # AUTO-D√âTECTION DE L'ARCHITECTURE (comme train.py)
    # =========================================================================

    # D√©tecter depuis le checkpoint
    is_dual_binary = model_config.get('is_dual_binary', False)
    indicator_for_metrics_saved = model_config.get('indicator_for_metrics', None)

    # D√©tecter depuis les metadata du dataset
    if metadata and 'label_names' in metadata and len(metadata['label_names']) == 2:
        is_dual_binary = True
        if not indicator_for_metrics_saved:
            label_name = metadata['label_names'][0]  # Ex: 'rsi_dir'
            indicator_for_metrics_saved = label_name.split('_')[0].upper()  # 'RSI'

    # D√©tecter le nombre de features et outputs depuis les donn√©es
    n_features_detected = X_test.shape[2]
    n_outputs_detected = Y_test.shape[1]

    logger.info(f"\nüîç Architecture d√©tect√©e:")
    logger.info(f"  Features: {n_features_detected}")
    logger.info(f"  Outputs: {n_outputs_detected}")
    logger.info(f"  Dual-Binary: {is_dual_binary}")
    if indicator_for_metrics_saved:
        logger.info(f"  Indicateur: {indicator_for_metrics_saved}")
    if metadata and 'filter_type' in metadata:
        logger.info(f"  Filtre: {metadata['filter_type'].upper()}")

    # Utiliser num_outputs de la config ou celui d√©tect√© depuis les donn√©es
    num_features = n_features_detected
    saved_num_outputs = model_config.get('num_outputs', n_outputs_detected)

    if saved_num_outputs != n_outputs_detected:
        logger.warning(f"  ‚ö†Ô∏è num_outputs mismatch: mod√®le={saved_num_outputs}, donn√©es={n_outputs_detected}")
        num_outputs = saved_num_outputs
    else:
        num_outputs = n_outputs_detected

    # Pr√©parer les noms d'indicateurs pour les m√©triques
    if is_dual_binary:
        # Dual-binary: ['Direction', 'Force']
        indicator_names_for_metrics = ['Direction', 'Force']
        logger.info(f"  Mode Dual-Binary d√©tect√©: {indicator_names_for_metrics}")
    elif single_indicator:
        # Single-output: ['MACD'] ou ['RSI'] etc.
        indicator_names_for_metrics = [indicator_name]
    else:
        # Multi-output: ['RSI', 'CCI', 'MACD'] (d√©faut)
        indicator_names_for_metrics = None  # compute_metrics utilisera les d√©fauts

    model, loss_fn = create_model(
        device=device,
        num_indicators=num_features,
        num_outputs=num_outputs,
        cnn_filters=model_config.get('cnn_filters', 64),
        lstm_hidden_size=model_config.get('lstm_hidden_size', 64),
        lstm_num_layers=model_config.get('lstm_num_layers', 2),
        lstm_dropout=model_config.get('lstm_dropout', 0.2),
        dense_hidden_size=model_config.get('dense_hidden_size', 32),
        dense_dropout=model_config.get('dense_dropout', 0.3),
        use_layer_norm=model_config.get('use_layer_norm', True),  # Par d√©faut True pour r√©trocompatibilit√©
        use_bce_with_logits=model_config.get('use_bce_with_logits', True),  # Par d√©faut True pour r√©trocompatibilit√©
        use_shortcut=model_config.get('use_shortcut', False),
        shortcut_steps=model_config.get('shortcut_steps', 5),
        use_temporal_gate=model_config.get('use_temporal_gate', False),
    )

    # Charger poids
    model.load_state_dict(checkpoint['model_state_dict'])

    logger.info(f"\n‚úÖ Mod√®le charg√©:")
    logger.info(f"  √âpoque: {checkpoint['epoch']}")
    logger.info(f"  Val Loss: {checkpoint['val_loss']:.4f}")
    logger.info(f"  Val Acc: {checkpoint['val_accuracy']:.3f}")
    if indicator_for_metrics_saved:
        logger.info(f"  Indicateur: {indicator_for_metrics_saved}")
    if model_config:
        logger.info(f"  Config: CNN={model_config.get('cnn_filters')}, "
                   f"LSTM={model_config.get('lstm_hidden_size')}x{model_config.get('lstm_num_layers')}")

    # =========================================================================
    # 5. √âVALUATION
    # =========================================================================
    logger.info("\n5. √âvaluation sur test set...")

    metrics = evaluate_model(model, test_loader, loss_fn, device, indicator_names=indicator_names_for_metrics)

    # Affichage des m√©triques selon le mode
    if is_dual_binary:
        # Dual-binary: afficher Direction et Force s√©par√©ment
        logger.info(f"\nüìä R√©sultats Test:")
        logger.info(f"  Loss: {metrics['loss']:.4f}, Avg Acc: {metrics['avg_accuracy']:.3f}")
        logger.info(f"  Direction: Acc={metrics.get('Direction_accuracy', 0):.3f}, "
                   f"F1={metrics.get('Direction_f1', 0):.3f}, "
                   f"Prec={metrics.get('Direction_precision', 0):.3f}, "
                   f"Rec={metrics.get('Direction_recall', 0):.3f}")
        logger.info(f"  Force:     Acc={metrics.get('Force_accuracy', 0):.3f}, "
                   f"F1={metrics.get('Force_f1', 0):.3f}, "
                   f"Prec={metrics.get('Force_precision', 0):.3f}, "
                   f"Rec={metrics.get('Force_recall', 0):.3f}")
    else:
        logger.info(f"\n  Test Loss: {metrics['loss']:.4f}")

    # Afficher tableau complet
    print_metrics_table(metrics, indicator_names=indicator_names_for_metrics)

    # =========================================================================
    # 6. SAUVEGARDER R√âSULTATS
    # =========================================================================
    logger.info("\n6. Sauvegarde des r√©sultats...")

    results_path = Path(RESULTS_DIR) / 'test_results.json'
    results_path.parent.mkdir(parents=True, exist_ok=True)

    with open(results_path, 'w') as f:
        json.dump(metrics, f, indent=2)

    logger.info(f"  R√©sultats sauvegard√©s: {results_path}")

    # =========================================================================
    # R√âSUM√â FINAL
    # =========================================================================
    logger.info("\n" + "="*80)
    logger.info("‚úÖ √âVALUATION TERMIN√âE")
    logger.info("="*80)

    logger.info(f"\nR√©sultats cl√©s:")
    logger.info(f"  Test Loss: {metrics['loss']:.4f}")

    if is_dual_binary:
        # Mode dual-binary: afficher Direction et Force
        logger.info(f"  Mode: Dual-Binary ({indicator_for_metrics_saved or 'INDICATOR'})")
        logger.info(f"  Avg Accuracy: {metrics['avg_accuracy']:.3f}")
        logger.info(f"  Direction - Acc: {metrics.get('Direction_accuracy', 0):.3f}, F1: {metrics.get('Direction_f1', 0):.3f}")
        logger.info(f"  Force - Acc: {metrics.get('Force_accuracy', 0):.3f}, F1: {metrics.get('Force_f1', 0):.3f}")
    elif single_indicator:
        # Mode single-output
        logger.info(f"  Indicateur: {indicator_name}")
        logger.info(f"  Accuracy: {metrics['avg_accuracy']:.3f}")
        logger.info(f"  F1: {metrics['avg_f1']:.3f}")
    else:
        # Mode multi-output
        logger.info(f"  Accuracy moyenne: {metrics['avg_accuracy']:.3f}")
        logger.info(f"  F1 moyen: {metrics['avg_f1']:.3f}")

    # Comparaison avec baseline (50% = hasard)
    baseline = 0.50
    improvement = (metrics['avg_accuracy'] - baseline) / baseline * 100

    logger.info(f"\nüìà Am√©lioration vs baseline (hasard):")
    logger.info(f"  Baseline: {baseline:.1%}")
    logger.info(f"  Mod√®le: {metrics['avg_accuracy']:.1%}")
    logger.info(f"  Gain: {improvement:+.1f}%")

    # Objectif selon le mode
    if is_dual_binary:
        # Objectif dual-binary: Direction 85%+, Force 65-70%+
        dir_acc = metrics.get('Direction_accuracy', 0)
        force_acc = metrics.get('Force_accuracy', 0)

        logger.info(f"\nüéØ Objectifs Dual-Binary:")
        if dir_acc >= 0.85:
            logger.info(f"  Direction: {dir_acc:.1%} ‚úÖ (objectif 85%+)")
        else:
            logger.info(f"  Direction: {dir_acc:.1%} ‚ö†Ô∏è (objectif 85%+)")

        if force_acc >= 0.65:
            logger.info(f"  Force: {force_acc:.1%} ‚úÖ (objectif 65-70%+)")
        else:
            logger.info(f"  Force: {force_acc:.1%} ‚ö†Ô∏è (objectif 65-70%+)")
    else:
        # Objectif classique: 70%+
        if metrics['avg_accuracy'] >= 0.70:
            logger.info(f"\nüéØ Objectif 70%+ atteint ! ‚úÖ")
        else:
            logger.info(f"\n‚ö†Ô∏è Objectif 70%+ pas encore atteint")
            logger.info(f"   Suggestions:")
            logger.info(f"   - Augmenter NUM_EPOCHS")
            logger.info(f"   - Ajuster hyperparam√®tres (CNN_FILTERS, LSTM_HIDDEN_SIZE)")
            logger.info(f"   - V√©rifier qualit√© des labels")


if __name__ == '__main__':
    main()
