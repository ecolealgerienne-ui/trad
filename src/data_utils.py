"""
Utilitaires de manipulation de donn√©es pour le projet IA trading.

Ce module contient les fonctions de chargement, pr√©paration et split des donn√©es.

‚ö†Ô∏è R√àGLE CRITIQUE : Split TEMPOREL strict pour √©viter data leakage!
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

from constants import (
    BTC_DATA_FILE, ETH_DATA_FILE,
    BTC_CANDLES, ETH_CANDLES,
    TRIM_EDGES,
    TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT,
    RANDOM_SEED
)


def load_crypto_data(filepath, n_candles=None, asset_name='CRYPTO'):
    """
    Charge un fichier CSV de donn√©es crypto.

    Args:
        filepath : Chemin vers le fichier CSV
        n_candles : Nombre de bougies √† charger (les derni√®res), None = toutes
        asset_name : Nom de l'actif (pour logs)

    Returns:
        DataFrame avec colonnes : timestamp, open, high, low, close, volume
    """
    filepath = Path(filepath)

    if not filepath.exists():
        raise FileNotFoundError(f"Fichier non trouv√© : {filepath}")

    logger.info(f"üìÇ Chargement {asset_name} : {filepath}")

    # Charger CSV (essayer diff√©rents s√©parateurs)
    # D'abord essayer avec virgule (format standard)
    df = pd.read_csv(filepath)

    # Si le fichier utilise des point-virgules, on aura une seule colonne
    if len(df.columns) == 1 and ';' in df.columns[0]:
        df = pd.read_csv(filepath, sep=';')

    # Normaliser les noms de colonnes (majuscules ‚Üí minuscules)
    df.columns = df.columns.str.lower()

    # Renommer colonnes si n√©cessaire
    column_mapping = {
        'date': 'timestamp',
        'time': 'timestamp'
    }
    df.rename(columns=column_mapping, inplace=True)

    # V√©rifier colonnes requises (volume optionnel)
    required_cols = ['timestamp', 'open', 'high', 'low', 'close']
    missing_cols = set(required_cols) - set(df.columns)
    if missing_cols:
        raise ValueError(f"Colonnes manquantes : {missing_cols}")

    # Ajouter colonne volume si absente (avec valeur par d√©faut)
    if 'volume' not in df.columns:
        df['volume'] = 1.0  # Valeur par d√©faut (pas utilis√©e pour l'instant)
        logger.warning(f"  ‚ö†Ô∏è Colonne 'volume' absente, ajout√©e avec valeur par d√©faut")

    # Convertir timestamp en datetime
    # Le timestamp peut √™tre en millisecondes (epoch) ou format date
    try:
        # Essayer conversion depuis epoch (millisecondes)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    except:
        # Sinon parser comme date
        df['timestamp'] = pd.to_datetime(df['timestamp'])

    # Prendre les derni√®res n bougies
    if n_candles is not None and len(df) > n_candles:
        df = df.tail(n_candles).reset_index(drop=True)
        logger.info(f"  ‚Üí {len(df):,} derni√®res bougies charg√©es")
    else:
        logger.info(f"  ‚Üí {len(df):,} bougies charg√©es")

    return df


def trim_edges(df, trim_start=TRIM_EDGES, trim_end=TRIM_EDGES):
    """
    Enl√®ve les bords (warm-up + artifacts des filtres).

    Args:
        df : DataFrame
        trim_start : Nombre de bougies √† enlever au d√©but
        trim_end : Nombre de bougies √† enlever √† la fin

    Returns:
        DataFrame trim√©
    """
    if len(df) <= trim_start + trim_end:
        raise ValueError(f"Dataset trop petit ({len(df)}) pour trim ({trim_start}+{trim_end})")

    df_trimmed = df.iloc[trim_start:-trim_end].reset_index(drop=True)

    logger.info(f"‚úÇÔ∏è Trim edges : {len(df):,} ‚Üí {len(df_trimmed):,} bougies")
    logger.info(f"  Enlev√© : {trim_start} d√©but + {trim_end} fin")

    return df_trimmed


def temporal_split(data, train_ratio=TRAIN_SPLIT, val_ratio=VAL_SPLIT, test_ratio=TEST_SPLIT,
                   shuffle_train=True, random_seed=RANDOM_SEED):
    """
    Split temporel: Test √† la fin, Val √©chantillonn√© de partout.

    Strat√©gie:
    - TEST = toujours les donn√©es les plus r√©centes (fin du dataset)
    - VAL = √©chantillonn√© al√©atoirement du reste (meilleure repr√©sentativit√©)
    - TRAIN = le reste

    Avantage: Val ne surfit pas √† une p√©riode sp√©cifique, meilleur pour
    un re-entra√Ænement mensuel.

    Args:
        data : DataFrame de s√©ries temporelles (ordre chronologique)
        train_ratio : Proportion pour train (d√©faut: 0.7)
        val_ratio : Proportion pour validation (d√©faut: 0.15)
        test_ratio : Proportion pour test (d√©faut: 0.15)
        shuffle_train : Si True, shuffle le train (APR√àS split)
        random_seed : Seed pour reproductibilit√©

    Returns:
        train, val, test : DataFrames splitt√©s
    """
    # V√©rifier ratios
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 0.001:
        raise ValueError(f"Les ratios doivent sommer √† 1.0 (actuellement: {total_ratio})")

    n_total = len(data)
    if n_total == 0:
        raise ValueError("Dataset vide")

    # 1. TEST = toujours √† la fin (donn√©es les plus r√©centes)
    n_test = int(n_total * test_ratio)
    test_data = data.iloc[-n_test:].copy()
    remaining = data.iloc[:-n_test].copy()

    # 2. VAL = √©chantillonn√© al√©atoirement du reste
    n_val = int(n_total * val_ratio)
    val_data = remaining.sample(n=n_val, random_state=random_seed)
    val_indices = val_data.index

    # 3. TRAIN = le reste (apr√®s avoir retir√© val)
    train_data = remaining.drop(val_indices).copy()

    logger.info(f"üìä Split temporel (Test=fin, Val=√©chantillonn√©):")
    logger.info(f"  Train: {len(train_data):,} bougies ({len(train_data)/n_total:.0%})")
    logger.info(f"  Val:   {len(val_data):,} bougies ({val_ratio:.0%}) - √©chantillonn√© de partout")
    logger.info(f"  Test:  {len(test_data):,} bougies ({test_ratio:.0%}) - FIN du dataset (plus r√©cent)")

    # Shuffle train (m√©lange les batches)
    if shuffle_train:
        train_data = train_data.sample(frac=1, random_state=random_seed).reset_index(drop=True)
        logger.info(f"  ‚úÖ Train shuffled")

    # Reset index pour val et test
    val_data = val_data.reset_index(drop=True)
    test_data = test_data.reset_index(drop=True)

    # V√©rifier coh√©rence
    assert len(train_data) + len(val_data) + len(test_data) == n_total, \
        "Erreur de split : longueur totale incorrecte"

    return train_data, val_data, test_data


def load_and_split_btc_eth(btc_candles=BTC_CANDLES, eth_candles=ETH_CANDLES,
                            trim_start=TRIM_EDGES, trim_end=TRIM_EDGES,
                            train_ratio=TRAIN_SPLIT, val_ratio=VAL_SPLIT, test_ratio=TEST_SPLIT):
    """
    Charge BTC+ETH, trim les edges, combine, et fait un split temporel.

    Pipeline complet :
    1. Charger BTC et ETH
    2. Prendre les derni√®res N bougies de chaque
    3. Trim edges (warm-up + artifacts)
    4. Combiner BTC + ETH
    5. Split temporel (train/val/test)

    Args:
        btc_candles : Nombre de bougies BTC √† charger
        eth_candles : Nombre de bougies ETH √† charger
        trim_start : Bougies √† enlever au d√©but
        trim_end : Bougies √† enlever √† la fin
        train_ratio : Ratio train
        val_ratio : Ratio validation
        test_ratio : Ratio test

    Returns:
        train, val, test : DataFrames pr√™ts pour l'entra√Ænement

    Example:
        >>> train, val, test = load_and_split_btc_eth()
        >>> print(f"Train: {len(train):,}, Val: {len(val):,}, Test: {len(test):,}")
    """
    logger.info("="*80)
    logger.info("CHARGEMENT ET PR√âPARATION DES DONN√âES")
    logger.info("="*80)

    # Charger BTC
    btc = load_crypto_data(BTC_DATA_FILE, n_candles=btc_candles, asset_name='BTC')

    # Charger ETH
    eth = load_crypto_data(ETH_DATA_FILE, n_candles=eth_candles, asset_name='ETH')

    # Trim edges (enlever warm-up + artifacts)
    btc_trimmed = trim_edges(btc, trim_start=trim_start, trim_end=trim_end)
    eth_trimmed = trim_edges(eth, trim_start=trim_start, trim_end=trim_end)

    # Combiner (ordre chronologique pr√©serv√©)
    all_data = pd.concat([btc_trimmed, eth_trimmed], ignore_index=True)
    logger.info(f"üîó Combinaison BTC + ETH : {len(all_data):,} bougies totales")

    # Split temporel (CRITIQUE : pas de shuffle avant!)
    train, val, test = temporal_split(
        all_data,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=test_ratio,
        shuffle_train=True  # Shuffle APR√àS split
    )

    logger.info("="*80)
    logger.info("‚úÖ DONN√âES PR√äTES")
    logger.info("="*80)

    return train, val, test


def validate_no_leakage(train, val, test, n_check=5):
    """
    Valide qu'il n'y a pas de data leakage entre train/val/test.

    V√©rifie que les timestamps sont bien s√©par√©s temporellement.

    Args:
        train, val, test : DataFrames des 3 sets
        n_check : Nombre de lignes √† v√©rifier aux fronti√®res

    Raises:
        AssertionError si data leakage d√©tect√©
    """
    logger.info("üîç Validation : V√©rification data leakage...")

    # V√©rifier que les timestamps sont ordonn√©s
    if 'timestamp' in train.columns:
        # Derniers de train < Premiers de val
        train_last = train['timestamp'].iloc[-n_check:].max()
        val_first = val['timestamp'].iloc[:n_check].min()

        assert train_last < val_first, \
            f"Data leakage d√©tect√© : train_last ({train_last}) >= val_first ({val_first})"

        # Derniers de val < Premiers de test
        val_last = val['timestamp'].iloc[-n_check:].max()
        test_first = test['timestamp'].iloc[:n_check].min()

        assert val_last < test_first, \
            f"Data leakage d√©tect√© : val_last ({val_last}) >= test_first ({test_first})"

        logger.info("  ‚úÖ Pas de data leakage : timestamps bien s√©par√©s")
        logger.info(f"    Train max: {train_last}")
        logger.info(f"    Val range: {val_first} ‚Üí {val_last}")
        logger.info(f"    Test min: {test_first}")
    else:
        logger.warning("  ‚ö†Ô∏è Colonne 'timestamp' absente, validation partielle")

    logger.info("‚úÖ Validation r√©ussie : donn√©es propres")


# =============================================================================
# Exemple d'utilisation
# =============================================================================

if __name__ == '__main__':
    # Configurer logging
    logging.basicConfig(level=logging.INFO)

    # Charger et splitter les donn√©es
    train_data, val_data, test_data = load_and_split_btc_eth()

    # Valider pas de leakage
    validate_no_leakage(train_data, val_data, test_data)

    # Afficher stats
    print(f"\nüìä STATS FINALES:")
    print(f"  Train: {len(train_data):,} bougies")
    print(f"  Val:   {len(val_data):,} bougies")
    print(f"  Test:  {len(test_data):,} bougies")
    print(f"  Total: {len(train_data) + len(val_data) + len(test_data):,} bougies")
