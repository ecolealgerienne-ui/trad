"""
Utilitaires de manipulation de donn√©es pour le projet IA trading.

Ce module contient les fonctions de chargement, pr√©paration et split des donn√©es.

‚ö†Ô∏è R√àGLE CRITIQUE : Split TEMPOREL strict pour √©viter data leakage!
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

from constants import (
    BTC_DATA_FILE, ETH_DATA_FILE,
    BTC_CANDLES, ETH_CANDLES,
    TRIM_EDGES,
    TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT,
    RANDOM_SEED
)


def load_crypto_data(filepath, n_candles=None, asset_name='CRYPTO'):
    """
    Charge un fichier CSV de donn√©es crypto.

    Args:
        filepath : Chemin vers le fichier CSV
        n_candles : Nombre de bougies √† charger (les derni√®res), None = toutes
        asset_name : Nom de l'actif (pour logs)

    Returns:
        DataFrame avec colonnes : timestamp, open, high, low, close, volume
    """
    filepath = Path(filepath)

    if not filepath.exists():
        raise FileNotFoundError(f"Fichier non trouv√© : {filepath}")

    logger.info(f"üìÇ Chargement {asset_name} : {filepath}")

    # Charger CSV
    df = pd.read_csv(filepath)

    # V√©rifier colonnes requises
    required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
    missing_cols = set(required_cols) - set(df.columns)
    if missing_cols:
        raise ValueError(f"Colonnes manquantes : {missing_cols}")

    # Convertir timestamp en datetime
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    # Prendre les derni√®res n bougies
    if n_candles is not None and len(df) > n_candles:
        df = df.tail(n_candles).reset_index(drop=True)
        logger.info(f"  ‚Üí {len(df):,} derni√®res bougies charg√©es")
    else:
        logger.info(f"  ‚Üí {len(df):,} bougies charg√©es")

    return df


def trim_edges(df, trim_start=TRIM_EDGES, trim_end=TRIM_EDGES):
    """
    Enl√®ve les bords (warm-up + artifacts des filtres).

    Args:
        df : DataFrame
        trim_start : Nombre de bougies √† enlever au d√©but
        trim_end : Nombre de bougies √† enlever √† la fin

    Returns:
        DataFrame trim√©
    """
    if len(df) <= trim_start + trim_end:
        raise ValueError(f"Dataset trop petit ({len(df)}) pour trim ({trim_start}+{trim_end})")

    df_trimmed = df.iloc[trim_start:-trim_end].reset_index(drop=True)

    logger.info(f"‚úÇÔ∏è Trim edges : {len(df):,} ‚Üí {len(df_trimmed):,} bougies")
    logger.info(f"  Enlev√© : {trim_start} d√©but + {trim_end} fin")

    return df_trimmed


def temporal_split(data, train_ratio=TRAIN_SPLIT, val_ratio=VAL_SPLIT, test_ratio=TEST_SPLIT,
                   shuffle_train=True, random_seed=RANDOM_SEED):
    """
    Split temporel STRICT sans data leakage.

    ‚ö†Ô∏è CRITIQUE : Cette fonction fait un split TEMPOREL, pas un shuffle global!
    Train = pass√©, Val = pr√©sent, Test = futur

    Args:
        data : DataFrame de s√©ries temporelles (ordre chronologique)
        train_ratio : Proportion pour train (d√©faut: 0.7)
        val_ratio : Proportion pour validation (d√©faut: 0.15)
        test_ratio : Proportion pour test (d√©faut: 0.15)
        shuffle_train : Si True, shuffle le train (APR√àS split)
        random_seed : Seed pour reproductibilit√©

    Returns:
        train, val, test : DataFrames splitt√©s temporellement

    Exemple:
        >>> train, val, test = temporal_split(all_data)
        >>> # Train : bougies 0-140k (shuffled)
        >>> # Val   : bougies 140k-170k (chronologique)
        >>> # Test  : bougies 170k-200k (chronologique)
    """
    # V√©rifier ratios
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 0.001:
        raise ValueError(f"Les ratios doivent sommer √† 1.0 (actuellement: {total_ratio})")

    n_total = len(data)
    if n_total == 0:
        raise ValueError("Dataset vide")

    # Calculer indices de split
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)

    # Split TEMPOREL (ordre chronologique pr√©serv√©)
    train_data = data.iloc[:n_train].copy()
    val_data = data.iloc[n_train:n_train+n_val].copy()
    test_data = data.iloc[n_train+n_val:].copy()

    logger.info(f"üìä Split temporel (SANS shuffle global - √©vite data leakage):")
    logger.info(f"  Train: {len(train_data):,} bougies ({train_ratio:.0%}) - indices [0:{n_train}]")
    logger.info(f"  Val:   {len(val_data):,} bougies ({val_ratio:.0%}) - indices [{n_train}:{n_train+n_val}]")
    logger.info(f"  Test:  {len(test_data):,} bougies ({test_ratio:.0%}) - indices [{n_train+n_val}:{n_total}]")

    # Shuffle train APR√àS split (√©vite biais d'ordre)
    if shuffle_train:
        train_data = train_data.sample(frac=1, random_state=random_seed).reset_index(drop=True)
        logger.info(f"  ‚úÖ Train shuffled (m√©lange batches, pas de leakage)")
    else:
        logger.info(f"  ‚ÑπÔ∏è Train NON shuffled (ordre chronologique pr√©serv√©)")

    # V√©rifier coh√©rence
    assert len(train_data) + len(val_data) + len(test_data) == n_total, \
        "Erreur de split : longueur totale incorrecte"

    return train_data, val_data, test_data


def load_and_split_btc_eth(btc_candles=BTC_CANDLES, eth_candles=ETH_CANDLES,
                            trim_start=TRIM_EDGES, trim_end=TRIM_EDGES,
                            train_ratio=TRAIN_SPLIT, val_ratio=VAL_SPLIT, test_ratio=TEST_SPLIT):
    """
    Charge BTC+ETH, trim les edges, combine, et fait un split temporel.

    Pipeline complet :
    1. Charger BTC et ETH
    2. Prendre les derni√®res N bougies de chaque
    3. Trim edges (warm-up + artifacts)
    4. Combiner BTC + ETH
    5. Split temporel (train/val/test)

    Args:
        btc_candles : Nombre de bougies BTC √† charger
        eth_candles : Nombre de bougies ETH √† charger
        trim_start : Bougies √† enlever au d√©but
        trim_end : Bougies √† enlever √† la fin
        train_ratio : Ratio train
        val_ratio : Ratio validation
        test_ratio : Ratio test

    Returns:
        train, val, test : DataFrames pr√™ts pour l'entra√Ænement

    Example:
        >>> train, val, test = load_and_split_btc_eth()
        >>> print(f"Train: {len(train):,}, Val: {len(val):,}, Test: {len(test):,}")
    """
    logger.info("="*80)
    logger.info("CHARGEMENT ET PR√âPARATION DES DONN√âES")
    logger.info("="*80)

    # Charger BTC
    btc = load_crypto_data(BTC_DATA_FILE, n_candles=btc_candles, asset_name='BTC')

    # Charger ETH
    eth = load_crypto_data(ETH_DATA_FILE, n_candles=eth_candles, asset_name='ETH')

    # Trim edges (enlever warm-up + artifacts)
    btc_trimmed = trim_edges(btc, trim_start=trim_start, trim_end=trim_end)
    eth_trimmed = trim_edges(eth, trim_start=trim_start, trim_end=trim_end)

    # Combiner (ordre chronologique pr√©serv√©)
    all_data = pd.concat([btc_trimmed, eth_trimmed], ignore_index=True)
    logger.info(f"üîó Combinaison BTC + ETH : {len(all_data):,} bougies totales")

    # Split temporel (CRITIQUE : pas de shuffle avant!)
    train, val, test = temporal_split(
        all_data,
        train_ratio=train_ratio,
        val_ratio=val_ratio,
        test_ratio=test_ratio,
        shuffle_train=True  # Shuffle APR√àS split
    )

    logger.info("="*80)
    logger.info("‚úÖ DONN√âES PR√äTES")
    logger.info("="*80)

    return train, val, test


def validate_no_leakage(train, val, test, n_check=5):
    """
    Valide qu'il n'y a pas de data leakage entre train/val/test.

    V√©rifie que les timestamps sont bien s√©par√©s temporellement.

    Args:
        train, val, test : DataFrames des 3 sets
        n_check : Nombre de lignes √† v√©rifier aux fronti√®res

    Raises:
        AssertionError si data leakage d√©tect√©
    """
    logger.info("üîç Validation : V√©rification data leakage...")

    # V√©rifier que les timestamps sont ordonn√©s
    if 'timestamp' in train.columns:
        # Derniers de train < Premiers de val
        train_last = train['timestamp'].iloc[-n_check:].max()
        val_first = val['timestamp'].iloc[:n_check].min()

        assert train_last < val_first, \
            f"Data leakage d√©tect√© : train_last ({train_last}) >= val_first ({val_first})"

        # Derniers de val < Premiers de test
        val_last = val['timestamp'].iloc[-n_check:].max()
        test_first = test['timestamp'].iloc[:n_check].min()

        assert val_last < test_first, \
            f"Data leakage d√©tect√© : val_last ({val_last}) >= test_first ({test_first})"

        logger.info("  ‚úÖ Pas de data leakage : timestamps bien s√©par√©s")
        logger.info(f"    Train max: {train_last}")
        logger.info(f"    Val range: {val_first} ‚Üí {val_last}")
        logger.info(f"    Test min: {test_first}")
    else:
        logger.warning("  ‚ö†Ô∏è Colonne 'timestamp' absente, validation partielle")

    logger.info("‚úÖ Validation r√©ussie : donn√©es propres")


# =============================================================================
# Exemple d'utilisation
# =============================================================================

if __name__ == '__main__':
    # Configurer logging
    logging.basicConfig(level=logging.INFO)

    # Charger et splitter les donn√©es
    train_data, val_data, test_data = load_and_split_btc_eth()

    # Valider pas de leakage
    validate_no_leakage(train_data, val_data, test_data)

    # Afficher stats
    print(f"\nüìä STATS FINALES:")
    print(f"  Train: {len(train_data):,} bougies")
    print(f"  Val:   {len(val_data):,} bougies")
    print(f"  Test:  {len(test_data):,} bougies")
    print(f"  Total: {len(train_data) + len(val_data) + len(test_data):,} bougies")
