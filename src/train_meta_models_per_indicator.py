#!/usr/bin/env python3
"""
Test Meta-ModÃ¨les SpÃ©cifiques par Indicateur (Option B)

Objectif: CrÃ©er des meta-modÃ¨les spÃ©cifiques pour amÃ©liorer chaque indicateur
en utilisant les AUTRES indicateurs comme features.

Exemples:
  - meta-RSI: Utilise CCI (ou CCI+MACD) pour prÃ©dire Y_true_RSI
  - meta-CCI: Utilise RSI (ou RSI+MACD) pour prÃ©dire Y_true_CCI
  - meta-MACD: Utilise RSI+CCI pour prÃ©dire Y_true_MACD

HypothÃ¨se: Un indicateur peut aider Ã  corriger les erreurs d'un autre.

Usage:
  # Test RSI avec CCI seul
  python src/train_meta_models_per_indicator.py --target rsi --use-indicators cci

  # Test RSI avec CCI+MACD
  python src/train_meta_models_per_indicator.py --target rsi --use-indicators cci macd

  # Test CCI avec RSI seul
  python src/train_meta_models_per_indicator.py --target cci --use-indicators rsi

  # Test MACD avec RSI+CCI
  python src/train_meta_models_per_indicator.py --target macd --use-indicators rsi cci
"""

import sys
import numpy as np
from pathlib import Path
import logging
import argparse
from typing import Dict, List, Tuple

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

DATASET_PATHS = {
    'macd': 'data/prepared/dataset_btc_eth_bnb_ada_ltc_macd_dual_binary_kalman.npz',
    'rsi': 'data/prepared/dataset_btc_eth_bnb_ada_ltc_rsi_dual_binary_kalman.npz',
    'cci': 'data/prepared/dataset_btc_eth_bnb_ada_ltc_cci_dual_binary_kalman.npz',
}


def load_indicator_predictions(indicator: str, split: str) -> Tuple[np.ndarray, np.ndarray]:
    """
    Charge les prÃ©dictions d'un indicateur.

    Returns:
        Y_pred: (n, 2) - [direction_proba, force_proba]
        Y_true: (n, 2) - [direction, force]
    """
    path = DATASET_PATHS[indicator]
    data = np.load(path, allow_pickle=True)

    Y_pred = data[f'Y_{split}_pred']  # Probabilities
    Y_true = data[f'Y_{split}']       # Ground truth

    return Y_pred, Y_true


def build_meta_features(
    target_indicator: str,
    use_indicators: List[str],
    split: str
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Construit les mÃ©ta-features pour un indicateur cible.

    Args:
        target_indicator: Indicateur Ã  amÃ©liorer (ex: 'rsi')
        use_indicators: Indicateurs Ã  utiliser comme features (ex: ['cci'] ou ['cci', 'macd'])
        split: 'train', 'val', ou 'test'

    Returns:
        X_meta: Features (n, k) oÃ¹ k = len(use_indicators) * 2
        Y_meta: Cible (n, 1) - Direction de target_indicator
    """
    logger.info(f"\nðŸ“¦ Construction mÃ©ta-features pour {target_indicator.upper()}")
    logger.info(f"   Using: {', '.join([i.upper() for i in use_indicators])}")

    # Charger target (pour Y_true)
    _, Y_target = load_indicator_predictions(target_indicator, split)
    Y_meta = Y_target[:, 0:1]  # Direction uniquement

    # Charger features (prÃ©dictions des autres indicateurs)
    features = []
    for indicator in use_indicators:
        Y_pred, _ = load_indicator_predictions(indicator, split)
        features.append(Y_pred)  # (n, 2) - [dir_proba, force_proba]
        logger.info(f"   âœ… {indicator.upper()}: {Y_pred.shape}")

    X_meta = np.concatenate(features, axis=1)  # (n, k)

    logger.info(f"\n   X_meta shape: {X_meta.shape}")
    logger.info(f"   Y_meta shape: {Y_meta.shape}")

    return X_meta, Y_meta


def train_and_evaluate_meta_model(
    target_indicator: str,
    use_indicators: List[str],
    model_type: str = 'logistic'
) -> Dict:
    """
    EntraÃ®ne et Ã©value un meta-modÃ¨le pour un indicateur.

    Args:
        target_indicator: Indicateur Ã  amÃ©liorer
        use_indicators: Indicateurs utilisÃ©s comme features
        model_type: 'logistic' ou 'rf'

    Returns:
        dict avec rÃ©sultats
    """
    logger.info("="*80)
    logger.info(f"ðŸŽ¯ META-MODÃˆLE POUR {target_indicator.upper()}")
    logger.info("="*80)
    logger.info(f"   Target: Y_true_{target_indicator.upper()} (Direction)")
    logger.info(f"   Features: {', '.join([f'{i.upper()}_pred' for i in use_indicators])}")

    # Charger donnÃ©es
    X_train, Y_train = build_meta_features(target_indicator, use_indicators, 'train')
    X_val, Y_val = build_meta_features(target_indicator, use_indicators, 'val')
    X_test, Y_test = build_meta_features(target_indicator, use_indicators, 'test')

    # Charger baseline (prÃ©dictions du modÃ¨le target seul)
    Y_baseline_pred, Y_baseline_true = load_indicator_predictions(target_indicator, 'test')
    Y_baseline_pred_binary = (Y_baseline_pred[:, 0] > 0.5).astype(int)
    Y_baseline_true_binary = Y_baseline_true[:, 0].astype(int)

    baseline_acc = accuracy_score(Y_baseline_true_binary, Y_baseline_pred_binary) * 100

    logger.info(f"\nðŸ“Š Baseline {target_indicator.upper()}: {baseline_acc:.2f}%")

    # EntraÃ®ner meta-modÃ¨le
    logger.info(f"\nâ³ EntraÃ®nement meta-modÃ¨le ({model_type})...")

    if model_type == 'logistic':
        model = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs')
    elif model_type == 'rf':
        model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
    else:
        raise ValueError(f"Model type inconnu: {model_type}")

    model.fit(X_train, Y_train.ravel())

    # PrÃ©dictions
    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)
    y_test_pred = model.predict(X_test)

    # MÃ©triques
    train_acc = accuracy_score(Y_train.ravel(), y_train_pred) * 100
    val_acc = accuracy_score(Y_val.ravel(), y_val_pred) * 100
    test_acc = accuracy_score(Y_test.ravel(), y_test_pred) * 100

    logger.info(f"\nðŸ“ˆ RÃ©sultats Meta-ModÃ¨le:")
    logger.info(f"   Train Accuracy: {train_acc:.2f}%")
    logger.info(f"   Val Accuracy:   {val_acc:.2f}%")
    logger.info(f"   Test Accuracy:  {test_acc:.2f}%")

    delta = test_acc - baseline_acc
    gap_train_val = abs(train_acc - val_acc)
    gap_val_test = abs(val_acc - test_acc)

    logger.info(f"\nðŸŽ¯ Comparaison:")
    logger.info(f"   Baseline:   {baseline_acc:.2f}%")
    logger.info(f"   Meta-Model: {test_acc:.2f}%")
    logger.info(f"   Delta:      {delta:+.2f}%")

    logger.info(f"\nðŸ“Š GÃ©nÃ©ralisation:")
    logger.info(f"   Gap Train/Val: {gap_train_val:.2f}%")
    logger.info(f"   Gap Val/Test:  {gap_val_test:.2f}%")

    # InterprÃ©tabilitÃ© (Logistic seulement)
    if model_type == 'logistic':
        logger.info(f"\nðŸ” Poids des features:")
        feature_names = []
        for indicator in use_indicators:
            feature_names.extend([f'{indicator.upper()}_dir', f'{indicator.upper()}_force'])

        for name, weight in zip(feature_names, model.coef_[0]):
            logger.info(f"     {name:12s}: {weight:+.4f}")

    # Verdict
    logger.info(f"\n" + "="*80)
    if delta > 1.0:
        verdict = "ðŸ† AMÃ‰LIORATION SIGNIFICATIVE"
        logger.info(f"âœ… {verdict}")
        logger.info(f"   â†’ {', '.join([i.upper() for i in use_indicators])} aide {target_indicator.upper()} (+{delta:.2f}%)")
    elif delta > 0.3:
        verdict = "âœ… AmÃ©lioration modÃ©rÃ©e"
        logger.info(f"{verdict}")
        logger.info(f"   â†’ Gain marginal avec {', '.join([i.upper() for i in use_indicators])}")
    elif delta >= 0:
        verdict = "âšª Neutre"
        logger.info(f"{verdict}")
        logger.info(f"   â†’ Pas d'amÃ©lioration significative")
    else:
        verdict = "âŒ DÃ©gradation"
        logger.info(f"{verdict}")
        logger.info(f"   â†’ {', '.join([i.upper() for i in use_indicators])} nuit Ã  {target_indicator.upper()}")

    logger.info("="*80)

    return {
        'target': target_indicator,
        'use_indicators': use_indicators,
        'baseline_acc': baseline_acc,
        'test_acc': test_acc,
        'delta': delta,
        'train_acc': train_acc,
        'val_acc': val_acc,
        'gap_train_val': gap_train_val,
        'gap_val_test': gap_val_test,
        'verdict': verdict,
    }


def main():
    parser = argparse.ArgumentParser(
        description='Test Meta-ModÃ¨les SpÃ©cifiques par Indicateur (Option B)'
    )
    parser.add_argument(
        '--target',
        type=str,
        required=True,
        choices=['rsi', 'cci', 'macd'],
        help="Indicateur Ã  amÃ©liorer (cible)"
    )
    parser.add_argument(
        '--use-indicators',
        type=str,
        nargs='+',
        required=True,
        choices=['rsi', 'cci', 'macd'],
        help="Indicateurs Ã  utiliser comme features (ex: cci, ou cci macd)"
    )
    parser.add_argument(
        '--model',
        type=str,
        default='logistic',
        choices=['logistic', 'rf'],
        help="Type de meta-modÃ¨le (dÃ©faut: logistic)"
    )

    args = parser.parse_args()

    # Validation: target ne doit pas Ãªtre dans use_indicators
    if args.target in args.use_indicators:
        logger.error(f"âŒ Erreur: target '{args.target}' ne peut pas Ãªtre dans use_indicators")
        logger.error(f"   Utilisation correcte: --target rsi --use-indicators cci macd")
        sys.exit(1)

    logger.info("="*80)
    logger.info("ðŸ§ª TEST META-MODÃˆLES SPÃ‰CIFIQUES PAR INDICATEUR (Option B)")
    logger.info("="*80)

    # EntraÃ®ner et Ã©valuer
    results = train_and_evaluate_meta_model(
        target_indicator=args.target,
        use_indicators=args.use_indicators,
        model_type=args.model
    )

    # RÃ©sumÃ© final
    logger.info(f"\n" + "="*80)
    logger.info(f"ðŸ“‹ RÃ‰SUMÃ‰ FINAL")
    logger.info(f"="*80)
    logger.info(f"\n   Target: {results['target'].upper()}")
    logger.info(f"   Features: {', '.join([i.upper() for i in results['use_indicators']])}")
    logger.info(f"   Baseline: {results['baseline_acc']:.2f}%")
    logger.info(f"   Meta-Model: {results['test_acc']:.2f}%")
    logger.info(f"   Delta: {results['delta']:+.2f}%")
    logger.info(f"   Verdict: {results['verdict']}")

    logger.info(f"\nðŸ’¡ Prochaines Ã©tapes:")
    if results['delta'] > 1.0:
        logger.info(f"   âœ… Utiliser ce meta-modÃ¨le en production")
        logger.info(f"   âœ… Tester en backtest pour mesurer impact Win Rate")
    elif results['delta'] > 0.3:
        logger.info(f"   â†’ Tester avec d'autres combinaisons d'indicateurs")
        logger.info(f"   â†’ Essayer Random Forest si Logistic utilisÃ©")
    else:
        logger.info(f"   â†’ Pas d'amÃ©lioration significative")
        logger.info(f"   â†’ Essayer d'autres combinaisons ou revenir Ã  Profitability Relabeling")

    logger.info(f"\n" + "="*80)


if __name__ == '__main__':
    sys.exit(main())
