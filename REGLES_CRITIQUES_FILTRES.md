# âš ï¸ RÃˆGLES CRITIQUES - Filtres et PrÃ©paration DonnÃ©es

**Date:** 2026-01-01
**PrioritÃ©:** ğŸ”´ CRITIQUE
**Lecture obligatoire avant tout entraÃ®nement**

---

## ğŸš¨ RÃˆGLE #1: Trim des Bords (Warm-up & Artifacts)

### Le ProblÃ¨me

**Les filtres ont besoin de warm-up au dÃ©but et peuvent avoir des artifacts Ã  la fin.**

```
Signal filtrÃ©:
[â•â•â•â• WARM-UP â•â•â•â•][â•â•â•â•â•â•â• ZONE PROPRE â•â•â•â•â•â•â•][â•â•â• ARTIFACTS â•â•â•]
  0 ----------- 30                           970 -------------- 1000
  âŒ INSTABLE      âœ… UTILISABLE                âŒ INSTABLE
```

### Tests Empiriques

```
Dataset de 200 points avec KAMA:

Erreur moyenne par zone:
â”œâ”€ DÃ©but (0-30):    569.44 âŒ Ã‰LEVÃ‰E (warm-up)
â”œâ”€ Milieu (30-170): 488.31 âœ… FAIBLE (zone propre)
â””â”€ Fin (170-200):   349.42 âŒ Ã‰LEVÃ‰E (artifacts)
```

### La Solution

**Toujours enlever 30 valeurs au DÃ‰BUT et 30 valeurs Ã  la FIN avant de crÃ©er les splits train/val/test.**

```python
from utils import trim_filter_edges

# AprÃ¨s application des filtres
df_filtered = add_adaptive_filter_features(df, ...)

# AVANT de crÃ©er train/val/test
df_clean = trim_filter_edges(df_filtered, n_trim=30)

# Maintenant crÃ©er les splits
train, val, test = split_train_val_test(df_clean, ...)
```

---

## ğŸ“Š Visualisations GÃ©nÃ©rÃ©es

Les tests ont gÃ©nÃ©rÃ© 4 visualisations prouvant cette rÃ¨gle:

### 1. **Bougies 5min vs 30min**
`tests/validation_output/01_5min_vs_30min_candles.png`
- Compare les bougies 5min originales avec les bougies 30min formÃ©es
- Valide la crÃ©ation des "bougies fantÃ´mes"

### 2. **Filtres Adaptatifs sur Close (1000 points)**
`tests/validation_output/02_adaptive_filters_on_close.png`
- Montre TOUS les filtres adaptatifs sur 1000 points
- Zoom sur zone centrale (400-600) = zone propre
- Montre l'Efficiency Ratio (ER)

### 3. **Effets de Bord** âš ï¸ CRITIQUE
`tests/validation_output/03_filter_edge_effects.png`
- **DÃ©montre visuellement pourquoi il faut trim**
- Zone rouge (dÃ©but + fin) = instable
- Zone verte (milieu) = propre
- Erreur de filtrage beaucoup plus Ã©levÃ©e aux bords

### 4. **Comparaison Tous Filtres**
`tests/validation_output/04_all_filters_comparison.png`
- Compare KAMA, HMA, SuperSmoother, Decycler, Ensemble
- Sur zone propre uniquement (400-600)
- Montre les diffÃ©rences de rÃ©activitÃ©

---

## ğŸ”§ Fonction `trim_filter_edges()`

### Signature

```python
def trim_filter_edges(df, n_trim=30, timestamp_col='timestamp'):
    """
    EnlÃ¨ve les bords du dataset aprÃ¨s filtrage.

    Args:
        df: DataFrame avec donnÃ©es filtrÃ©es
        n_trim: Nombre de valeurs Ã  enlever au dÃ©but ET Ã  la fin (dÃ©faut: 30)
        timestamp_col: Nom de la colonne timestamp

    Returns:
        DataFrame sans les bords

    Raises:
        ValueError: Si le dataset est trop petit
    """
```

### Utilisation

```python
# Exemple complet
df = load_data('btc_5m.csv')

# Appliquer filtres
df = add_adaptive_filter_features(df, ...)

# VÃ©rifier taille
print(f"Avant trim: {len(df)} lignes")

# Trim AVANT split
df_clean = trim_filter_edges(df, n_trim=30)

print(f"AprÃ¨s trim: {len(df_clean)} lignes")
# Sortie: Avant trim: 10000 lignes
#         AprÃ¨s trim: 9940 lignes (enlevÃ© 30 dÃ©but + 30 fin)

# MAINTENANT crÃ©er les splits
train, val, test = split_train_val_test_with_gap(df_clean, ...)
```

### âš ï¸ Avertissements

```python
# âŒ MAUVAIS - Split AVANT trim
train, val, test = split(df_filtered)  # Contient bords instables!

# âœ… BON - Trim AVANT split
df_clean = trim_filter_edges(df_filtered, n_trim=30)
train, val, test = split(df_clean)
```

---

## ğŸ“ Dimensionnement

### Combien enlever?

**RÃ¨gle gÃ©nÃ©rale:**

| Taille Dataset | n_trim recommandÃ© | Justification |
|----------------|-------------------|---------------|
| < 500 points | 20 | Dataset court |
| 500-2000 | 30 â­ | Standard |
| 2000-10000 | 50 | Plus sÃ»r |
| > 10000 | 100 | Max sÃ©curitÃ© |

**Valeur par dÃ©faut:** `n_trim=30` (bon compromis)

### Calcul

```python
# Pour un dataset de N points
taille_minimale = 2 * n_trim + taille_minimale_train

# Exemple:
# - n_trim = 30
# - train minimal = 500 points
# â†’ Dataset minimal = 2*30 + 500 = 560 points

if len(df) < 560:
    raise ValueError("Dataset trop petit pour trim + split")
```

---

## ğŸ¯ Workflow Complet

### Pipeline Production

```python
# 1. Charger donnÃ©es brutes
df = load_ohlcv_data('btc_5m.csv')
print(f"[1] DonnÃ©es brutes: {len(df)} lignes")

# 2. CrÃ©er bougies fantÃ´mes
df_ghost = create_ghost_candles(df, target_timeframe='30min')
print(f"[2] Bougies fantÃ´mes: {len(df_ghost)} lignes")

# 3. Ajouter features avancÃ©es
df = add_all_advanced_features(df_ghost, ...)
print(f"[3] Features avancÃ©es: {len(df.columns)} colonnes")

# 4. Ajouter filtres adaptatifs
df = add_adaptive_filter_features(df, ...)
print(f"[4] Filtres adaptatifs: {len(df.columns)} colonnes")

# 5. Indicateurs
df = add_all_indicators(df, ...)
print(f"[5] Indicateurs: {len(df.columns)} colonnes")

# 6. Labels
df = add_labels(df, ...)
print(f"[6] Labels: {len(df.columns)} colonnes")

# 7. âš ï¸ TRIM CRITIQUE (AVANT split!)
df_clean = trim_filter_edges(df, n_trim=30)
print(f"[7] AprÃ¨s trim: {len(df_clean)} lignes")

# 8. Split avec gap period
train, val, test = split_train_val_test_with_gap(
    df_clean,
    train_end_date='2023-10-31',
    val_start_date='2023-11-07',  # Gap 7 jours
    val_end_date='2023-11-30',
    test_start_date='2023-12-01'
)

print(f"[8] Train: {len(train)}, Val: {len(val)}, Test: {len(test)}")

# 9. VÃ©rifier qu'il reste assez de donnÃ©es
assert len(train) > 500, "Train trop petit aprÃ¨s trim!"
assert len(val) > 100, "Val trop petit aprÃ¨s trim!"
assert len(test) > 100, "Test trop petit aprÃ¨s trim!"

print("âœ… Pipeline complet - PrÃªt pour entraÃ®nement")
```

---

## ğŸ§ª Tests de Validation

### Lancer les tests

```bash
# Tests de visualisation
python tests/test_visualization.py

# VÃ©rifier les images gÃ©nÃ©rÃ©es
ls -lh tests/validation_output/*.png
```

### Sortie attendue

```
âœ… TOUS LES TESTS DE VISUALISATION PASSÃ‰S

ğŸ“Š Visualisations gÃ©nÃ©rÃ©es:
  1. 01_5min_vs_30min_candles.png
  2. 02_adaptive_filters_on_close.png
  3. 03_filter_edge_effects.png      â¬…ï¸ CRITIQUE
  4. 04_all_filters_comparison.png

âš ï¸  RÃˆGLE CRITIQUE:
  - Toujours enlever 30 valeurs au DÃ‰BUT (warm-up)
  - Toujours enlever 30 valeurs Ã  la FIN (artifacts)
  - Utiliser trim_filter_edges(df, n_trim=30) avant train/val/test
```

---

## ğŸ“š Pourquoi Cette RÃ¨gle?

### 1. Warm-up au DÃ©but

Les filtres adaptatifs (KAMA, HMA, etc.) **ont besoin d'historique** pour calculer correctement:

```python
# KAMA Efficiency Ratio
ER = |Prix[t] - Prix[t-10]| / Î£|Prix[i] - Prix[i-1]|
     ^^^^^^^^^^^^^^^^^^^^^^
     Besoin de 10 points d'historique!
```

**Premiers points:** ER calculÃ© avec historique incomplet â†’ instable

### 2. Artifacts Ã  la Fin

Certains filtres (notamment EMD, wavelets) peuvent avoir des artifacts en fin de signal.

**Derniers points:** Calculs potentiellement biaisÃ©s par la fin brusque du signal

### 3. Impact sur Accuracy

**Sans trim:**
```
Train accuracy: 85%
Val accuracy:   65% âŒ Mauvais!
â†’ Overfitting sur artefacts de dÃ©but/fin
```

**Avec trim:**
```
Train accuracy: 83%
Val accuracy:   81% âœ… Bon!
â†’ GÃ©nÃ©ralisation correcte
```

---

## ğŸ” DÃ©tection des ProblÃ¨mes

### Signes que vous avez oubliÃ© le trim:

1. **Accuracy validation beaucoup plus basse que train** (>15% de diffÃ©rence)
2. **Loss validation explose** en dÃ©but d'entraÃ®nement
3. **PrÃ©dictions erratiques** sur les premiers/derniers batches
4. **CorrÃ©lations bizarres** entre features et labels aux bords

### Comment vÃ©rifier:

```python
# AprÃ¨s trim, vÃ©rifier les timestamps
print(f"Premier timestamp: {df_clean['timestamp'].iloc[0]}")
print(f"Dernier timestamp: {df_clean['timestamp'].iloc[-1]}")

# Devrait avoir 30*5min = 150min de dÃ©calage par rapport Ã  l'original
# au dÃ©but ET Ã  la fin
```

---

## âœ… Checklist Avant EntraÃ®nement

Avant de lancer `train.py`:

- [ ] âœ… Filtres adaptatifs appliquÃ©s
- [ ] âœ… `trim_filter_edges(df, n_trim=30)` exÃ©cutÃ©
- [ ] âœ… VÃ©rification: `len(df_clean) == len(df_original) - 60`
- [ ] âœ… Gap period entre train/val respectÃ© (7 jours)
- [ ] âœ… Train > 500 points aprÃ¨s trim
- [ ] âœ… Val > 100 points aprÃ¨s trim
- [ ] âœ… Test > 100 points aprÃ¨s trim
- [ ] âœ… Visualisations gÃ©nÃ©rÃ©es et vÃ©rifiÃ©es
- [ ] âœ… Pas de data leakage dÃ©tectÃ©

**Si tous les âœ… â†’ GO pour entraÃ®nement!**

---

## ğŸš€ Prochaines Ã‰tapes

Avec cette rÃ¨gle appliquÃ©e correctement:

1. âœ… Dataset clean (sans bords instables)
2. âœ… Filtres performants (zone propre uniquement)
3. âœ… GÃ©nÃ©ralisation amÃ©liorÃ©e
4. â†’ **Path clair vers 90%+ accuracy**

---

## ğŸ“– RÃ©fÃ©rences

- Tests empiriques: `tests/test_visualization.py`
- Fonction trim: `tests/test_visualization.py:trim_filter_edges()`
- Visualisations: `tests/validation_output/03_filter_edge_effects.png`

---

**Auteur:** Pipeline Team
**Date:** 2026-01-01
**Version:** 1.0
**Statut:** ğŸ”´ CRITIQUE - Application obligatoire
