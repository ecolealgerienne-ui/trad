# ü§ñ Mod√®le CNN-LSTM Multi-Output - Guide Complet

**Date**: 2026-01-01
**Statut**: Pipeline complet impl√©ment√© ‚úÖ

---

## üìã Vue d'Ensemble

Ce projet impl√©mente un syst√®me de pr√©diction de tendance crypto utilisant un mod√®le CNN-LSTM multi-output pour pr√©dire la **pente (direction)** de 4 indicateurs techniques.

### Objectif

Pr√©dire si chaque indicateur technique va **monter** (label=1) ou **descendre** (label=0) au prochain timestep.

### Architecture

```
Input: (batch, 12, 4)  ‚Üê 12 timesteps √ó 4 indicateurs
  ‚Üì
CNN 1D (64 filters)    ‚Üê Extraction features
  ‚Üì
LSTM (64 hidden √ó 2)   ‚Üê Patterns temporels
  ‚Üì
Dense partag√© (32)     ‚Üê Repr√©sentation commune
  ‚Üì
4 t√™tes ind√©pendantes  ‚Üê RSI, CCI, BOL, MACD
  ‚Üì
Output: (batch, 4)     ‚Üê 4 probabilit√©s binaires
```

---

## üöÄ Quick Start

### 1. Installation

```bash
cd ~/projects/trad
pip install -r requirements.txt
```

### 2. V√©rifier les Donn√©es

```bash
python src/data_utils.py
```

**Attendu**: 199,600 bougies charg√©es (BTC 99,800 + ETH 99,800)

### 3. Test Pipeline Indicateurs

```bash
python src/indicators.py
```

**Attendu**: Datasets pr√™ts avec shapes:
- Train: X=(139,708, 12, 4), Y=(139,708, 4)
- Val: X=(29,928, 12, 4), Y=(29,928, 4)
- Test: X=(29,928, 12, 4), Y=(29,928, 4)

### 4. Test Mod√®le

```bash
python src/model.py
```

**Attendu**: Forward pass OK, m√©triques calcul√©es

### 5. Entra√Ænement

```bash
python src/train.py
```

**Dur√©e estim√©e**: 10-30 min (d√©pend CPU/GPU)

### 6. √âvaluation

```bash
python src/evaluate.py
```

**Attendu**: M√©triques sur test set + comparaison baseline

---

## üìÅ Structure du Projet

```
trad/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ constants.py           ‚Üê Toutes les constantes centralis√©es
‚îÇ   ‚îú‚îÄ‚îÄ data_utils.py          ‚Üê Chargement donn√©es (split temporel)
‚îÇ   ‚îú‚îÄ‚îÄ indicators.py          ‚Üê Calcul indicateurs + labels
‚îÇ   ‚îú‚îÄ‚îÄ model.py               ‚Üê Mod√®le CNN-LSTM + loss
‚îÇ   ‚îú‚îÄ‚îÄ train.py               ‚Üê Script d'entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py            ‚Üê Script d'√©valuation
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ SPEC_ARCHITECTURE_IA.md       ‚Üê Sp√©cification compl√®te
‚îÇ   ‚îú‚îÄ‚îÄ APPROCHE_IA_PREDICTION_PENTE.md  ‚Üê Approche IA (pr√©dire pente)
‚îÇ   ‚îú‚îÄ‚îÄ REGLE_CRITIQUE_DATA_LEAKAGE.md   ‚Üê Split temporel obligatoire
‚îÇ   ‚îî‚îÄ‚îÄ RESULTATS_DECYCLER_INDICATEURS.md ‚Üê Tests monde parfait
‚îÇ
‚îú‚îÄ‚îÄ models/                    ‚Üê Mod√®les sauvegard√©s
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth         ‚Üê Meilleur mod√®le
‚îÇ   ‚îî‚îÄ‚îÄ training_history.json  ‚Üê Historique entra√Ænement
‚îÇ
‚îú‚îÄ‚îÄ results/                   ‚Üê R√©sultats √©valuation
‚îÇ   ‚îî‚îÄ‚îÄ test_results.json      ‚Üê M√©triques test set
‚îÇ
‚îú‚îÄ‚îÄ GUIDE_TEST_DONNEES.md      ‚Üê Guide test chargement donn√©es
‚îî‚îÄ‚îÄ CLAUDE.md                  ‚Üê Ce fichier
```

---

## üéØ Pipeline Complet

### √âtape 1: Chargement Donn√©es

```python
from data_utils import load_and_split_btc_eth

train_df, val_df, test_df = load_and_split_btc_eth()
```

**Caract√©ristiques**:
- BTC: 100k bougies (les derni√®res)
- ETH: 100k bougies (les derni√®res)
- Trim edges: 100 d√©but + 100 fin (warm-up filtres)
- **Split temporel STRICT**: 70% train / 15% val / 15% test
- **Pas de shuffle global** (√©vite data leakage)

### √âtape 2: Calcul Indicateurs

```python
from indicators import prepare_datasets

datasets = prepare_datasets(train_df, val_df, test_df)
X_train, Y_train = datasets['train']
```

**Indicateurs normalis√©s (0-100)**:
1. RSI(14) - D√©j√† 0-100
2. CCI(20) - Normalis√© depuis -200/+200
3. Bollinger %B(20, 2œÉ) - Position dans bandes
4. MACD(12/26/9) - Histogram normalis√© dynamiquement

**Labels**:
- G√©n√©r√©s avec **Decycler parfait** (forward-backward, non-causal)
- Label = 1 si filtre[t-1] > filtre[t-2] (pente haussi√®re)
- Label = 0 sinon (pente baissi√®re)

**S√©quences**:
- Longueur: 12 timesteps
- Format: X=(N, 12, 4), Y=(N, 4)

### √âtape 3: Entra√Ænement

```python
from train import main

main()
```

**Hyperparam√®tres** (voir `constants.py`):
- Batch size: 32
- Learning rate: 0.001
- Epochs: 100 (max)
- Early stopping: 10 patience
- Optimizer: Adam

**Loss**:
- BCE multi-output
- Moyenne pond√©r√©e des 4 sorties (poids √©gaux par d√©faut)

**Early Stopping**:
- Surveille validation loss
- Arr√™te si pas d'am√©lioration pendant 10 √©poques
- Sauvegarde le meilleur mod√®le

### √âtape 4: √âvaluation

```python
from evaluate import main

main()
```

**M√©triques calcul√©es**:
- Par indicateur: Accuracy, Precision, Recall, F1
- Moyenne des 4 indicateurs
- **Vote majoritaire**: Moyenne des 4 pr√©dictions

---

## üìä R√©sultats Attendus

### Baseline (Hasard)

- Accuracy: ~50%
- F1: ~50%

### Objectif

- **Accuracy moyenne: ‚â•70%**
- F1 moyen: ‚â•70%
- Vote majoritaire: ‚â•70%

### Interpr√©tation

Si accuracy ~50% :
- ‚ö†Ô∏è Le mod√®le n'apprend pas (√©quivalent hasard)
- V√©rifier: data leakage, labels, architecture

Si accuracy 60-70% :
- ‚úÖ Le mod√®le apprend des patterns
- Am√©liorer: hyperparam√®tres, plus de donn√©es

Si accuracy ‚â•70% :
- üéØ Objectif atteint !
- Prochaine √©tape: Backtest r√©el

---

## ‚ö†Ô∏è Points Critiques

### 1. Data Leakage - √âVIT√â ‚úÖ

**Probl√®me potentiel**: Shuffle avant split
- S√©quences t et t+1 dans train ET test
- Accuracy artificielle 90%+ mais 50% en prod

**Solution impl√©ment√©e**:
- **Split temporel STRICT** dans `data_utils.py`
- Train = 70% premiers
- Val = 15% suivants
- Test = 15% derniers
- Shuffle APR√àS split (uniquement train)

### 2. Labels Non-Causaux - CORRECT ‚úÖ

**Approche**:
- Labels g√©n√©r√©s avec **Decycler parfait** (forward-backward)
- NON-CAUSAL (utilise le futur) mais OK car ce sont des **labels**
- Les **features** (indicateurs) sont CAUSALES

**R√®gle**:
- Input X: TOUJOURS causal (n'utilise que le pass√©)
- Labels Y: Peuvent √™tre non-causaux (v√©rit√© terrain)

### 3. Normalisation - CORRECT ‚úÖ

**Principe**:
- Tous les indicateurs normalis√©s 0-100
- Facilite apprentissage du r√©seau
- √âvite domination d'un indicateur

**Impl√©mentation**:
- RSI: D√©j√† 0-100
- CCI: Min-max -200/+200 ‚Üí 0-100
- Bollinger %B: 0-100
- MACD: Normalisation dynamique (rolling window)

---

## üîß Ajuster les Hyperparam√®tres

Tous dans `src/constants.py` :

### Architecture

```python
# CNN
CNN_FILTERS = 64          # Nombre de filtres (essayer 32, 64, 128)
CNN_KERNEL_SIZE = 3       # Taille kernel (essayer 3, 5)

# LSTM
LSTM_HIDDEN_SIZE = 64     # Taille hidden (essayer 32, 64, 128)
LSTM_NUM_LAYERS = 2       # Nombre de couches (essayer 1, 2, 3)
LSTM_DROPOUT = 0.2        # Dropout LSTM (essayer 0.1, 0.2, 0.3)

# Dense
DENSE_HIDDEN_SIZE = 32    # Taille couche dense (essayer 16, 32, 64)
DENSE_DROPOUT = 0.3       # Dropout dense (essayer 0.2, 0.3, 0.4)
```

### Entra√Ænement

```python
BATCH_SIZE = 32           # Batch size (essayer 16, 32, 64)
LEARNING_RATE = 0.001     # Learning rate (essayer 0.0001, 0.001, 0.01)
NUM_EPOCHS = 100          # √âpoques max (essayer 50, 100, 200)
EARLY_STOPPING_PATIENCE = 10  # Patience (essayer 5, 10, 20)
```

### Donn√©es

```python
SEQUENCE_LENGTH = 12      # Longueur s√©quences (essayer 6, 12, 24)
BTC_CANDLES = 100000      # Bougies BTC (essayer 50k, 100k, 200k)
ETH_CANDLES = 100000      # Bougies ETH (essayer 50k, 100k, 200k)
```

---

## üìà Monitoring

### Pendant l'entra√Ænement

Observer dans les logs:
- **Train loss**: Doit descendre progressivement
- **Val loss**: Doit descendre aussi (si monte ‚Üí overfitting)
- **Train accuracy**: Doit monter
- **Val accuracy**: Doit monter et rester proche de train

**Signes de bon entra√Ænement**:
- Val loss suit train loss
- Gap train/val ‚â§ 5%
- Accuracy > 50% (sinon = hasard)

**Signes de probl√®me**:
- Val loss monte pendant que train loss descend ‚Üí Overfitting
- Accuracy stagne √† ~50% ‚Üí Mod√®le n'apprend pas
- Loss explose ‚Üí Learning rate trop √©lev√©

### Apr√®s entra√Ænement

Fichiers g√©n√©r√©s:
- `models/best_model.pth` - Meilleur mod√®le
- `models/training_history.json` - Historique complet
- `results/test_results.json` - M√©triques test

Visualiser:
```python
import json
import matplotlib.pyplot as plt

with open('models/training_history.json') as f:
    history = json.load(f)

plt.plot(history['train_loss'], label='Train')
plt.plot(history['val_loss'], label='Val')
plt.legend()
plt.show()
```

---

## üéØ Prochaines √âtapes

### Si accuracy ‚â•70% atteinte :

1. **Backtest r√©el** sur donn√©es de production
2. **Trading strategy** bas√©e sur pr√©dictions
3. **Monitoring live** en conditions r√©elles

### Si accuracy <70% :

1. Augmenter `NUM_EPOCHS` (essayer 200)
2. Ajuster architecture (plus de CNN_FILTERS/LSTM_HIDDEN_SIZE)
3. Augmenter donn√©es (plus de BTC_CANDLES/ETH_CANDLES)
4. V√©rifier qualit√© des labels (distribution ~50/50)

---

## üìö Documentation Technique

### Fichiers de documentation

- `docs/SPEC_ARCHITECTURE_IA.md` - Sp√©cification compl√®te du mod√®le
- `docs/APPROCHE_IA_PREDICTION_PENTE.md` - Pourquoi pr√©dire la pente
- `docs/REGLE_CRITIQUE_DATA_LEAKAGE.md` - Data leakage et split temporel
- `docs/RESULTATS_DECYCLER_INDICATEURS.md` - Validation th√©orique

### Concepts cl√©s

**Decycler Parfait**:
- Filtre de Ehlers appliqu√© forward puis backward
- R√©sultat: Signal liss√© SANS lag temporel
- Utilisation: G√©n√©ration labels uniquement (non-causal OK)

**Split Temporel**:
- Train sur pass√©, valide sur futur
- Simule conditions r√©elles de trading
- √âvite data leakage massif

**Multi-Output**:
- 4 sorties ind√©pendantes (une par indicateur)
- Chaque sortie pr√©dit pente de son indicateur
- Vote majoritaire pour d√©cision finale

---

## ‚úÖ Checklist Avant Production

- [ ] Accuracy ‚â•70% sur test set
- [ ] Gap train/val ‚â§5%
- [ ] Vote majoritaire ‚â•70%
- [ ] Pas de data leakage (validation timestamps OK)
- [ ] Backtest sur donn√©es non vues
- [ ] Trading strategy d√©finie
- [ ] Risk management impl√©ment√©

---

**Cr√©√© par**: Claude Code
**Derni√®re MAJ**: 2026-01-01
**Version**: 1.0
