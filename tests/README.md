# Tests et Validation du Pipeline

Ce dossier contient les tests rigoureux pour valider chaque √©tape du pipeline de donn√©es.

**R√àGLE D'OR:** Toujours valider les donn√©es entre chaque √©tape avant de continuer. Un seul bug dans les donn√©es peut ruiner des semaines d'entra√Ænement GPU!

---

## üìã Scripts de Test

### 1. `quick_validation.py` - Validation Rapide ‚ö°

**Usage:**
```bash
python tests/quick_validation.py
```

**Ce qu'il teste:**
- ‚úÖ Cr√©ation des bougies fant√¥mes (6 steps par bougie 30min)
- ‚úÖ Int√©grit√© OHLC (H‚â•L, H‚â•O, H‚â•C, etc.)
- ‚úÖ Pr√©sence de toutes les features avanc√©es
- ‚úÖ Ranges corrects (step_index_norm [0.0-1.0], amplitude>0, etc.)
- ‚úÖ Pas de NaN inattendus

**Dur√©e:** ~5 secondes

**Quand l'utiliser:**
- Apr√®s chaque modification du code
- Avant de commit
- Pour v√©rifier rapidement que le pipeline fonctionne

---

### 2. `test_pipeline_validation.py` - Validation Compl√®te üìä

**Usage:**
```bash
python tests/test_pipeline_validation.py
```

**Ce qu'il teste:**
- ‚úÖ Bougies fant√¥mes avec visualisations
- ‚úÖ Features avanc√©es (velocity, log returns, Z-Score) + distributions
- ‚úÖ Data leakage (corr√©lations futures)
- ‚úÖ G√©n√©ration de graphiques de validation

**Sortie:**
- `tests/validation_output/01_ghost_candle_evolution.png`
- `tests/validation_output/02_advanced_features_distributions.png`
- `tests/validation_output/03_feature_evolution_per_step.png`
- `tests/validation_output/04_data_leakage_check.png`
- `tests/validation_output/validation_report.txt`

**Dur√©e:** ~30 secondes

**Quand l'utiliser:**
- Avant un entra√Ænement GPU
- Apr√®s int√©gration de nouvelles features
- Pour d√©bugger visuellement les donn√©es

---

## üéØ Checklist de Validation

Avant de lancer un entra√Ænement, v√©rifier:

### Donn√©es Brutes (5min)
- [ ] Pas de NaN dans OHLC
- [ ] Timestamps cons√©cutifs (pas de trous)
- [ ] OHLC integrity: H‚â•max(O,C), L‚â§min(O,C)
- [ ] Volume > 0

### Bougies Fant√¥mes (30min)
- [ ] Exactement 6 steps par bougie compl√®te
- [ ] Open constant dans une bougie
- [ ] High monotone croissant (ou constant)
- [ ] Low monotone d√©croissant (ou constant)
- [ ] Close = dernier close 5min

### Features Avanc√©es
- [ ] `velocity`: range raisonnable (pas >1.0)
- [ ] `amplitude`: toujours positive
- [ ] `acceleration`: mean proche de 0
- [ ] `ghost_high/low/close_log`: mean proche de 0
- [ ] `ghost_open_zscore`: mean~0, std~1
- [ ] `step_index_norm`: exactement [0.0, 1.0]

### Indicateurs Techniques
- [ ] RSI: range [0, 100]
- [ ] CCI: range raisonnable [-300, +300]
- [ ] MACD: pas de valeurs aberrantes
- [ ] Bollinger: upper > middle > lower

### Labels
- [ ] Distribution √©quilibr√©e (40-60% de chaque classe)
- [ ] Pas de NaN (sauf warm-up du filtre)
- [ ] Pas de data leakage (|corr| < 0.7 avec future)
- [ ] Corr√©lation id√©ale: 0.1-0.3

### Multi-Actifs (si applicable)
- [ ] Colonne `asset` pr√©sente
- [ ] Normalisation s√©par√©e par actif
- [ ] Pas de fuite inter-actifs
- [ ] Distribution √©quilibr√©e entre actifs

### Split Train/Val/Test
- [ ] Gap period respect√© (7 jours)
- [ ] Pas de chevauchement temporel
- [ ] Distribution labels similaire entre splits
- [ ] Taille suffisante (train>60%, val~20%, test~20%)

---

## üöÄ Exemples d'Usage

### Test Rapide apr√®s Modification
```bash
# Modifier le code
vim src/advanced_features.py

# Valider rapidement
python tests/quick_validation.py

# Si OK, commit
git add src/advanced_features.py
git commit -m "Add new feature"
```

### Validation Compl√®te avant GPU
```bash
# Valider avec visualisations
python tests/test_pipeline_validation.py

# V√©rifier les graphiques
ls -lh tests/validation_output/*.png

# Lire le rapport
cat tests/validation_output/validation_report.txt

# Si tout est OK, lancer l'entra√Ænement
python train.py --config config/model_v1.yaml
```

### Test sur Vraies Donn√©es
```bash
# Cr√©er dataset BTC
python src/data_pipeline.py \
  --input ../data_trad/BTCUSD_all_5m.csv \
  --output data/processed/btc_test.csv

# Valider le dataset
python tests/validate_dataset.py data/processed/btc_test.csv

# Si OK, cr√©er multi-asset
python example_multiasset_run.py
```

---

## üìä Interpr√©tation des R√©sultats

### ‚úÖ Succ√®s
```
============================================================
‚úÖ VALIDATION R√âUSSIE - Pipeline fonctionnel!
============================================================
```
**Action:** Continuer au prochain test ou lancer l'entra√Ænement.

### ‚ùå Erreurs Critiques
```
‚ùå VALIDATION √âCHOU√âE - 3 erreurs:
  - Certaines bougies n'ont pas 6 steps!
  - Amplitude n√©gative d√©tect√©e
  - Data leakage d√©tect√©: rsi_14 (corr=0.89)
```
**Action:**
1. Corriger les erreurs une par une
2. Relancer le test apr√®s chaque correction
3. NE PAS continuer tant qu'il reste des erreurs

### ‚ö†Ô∏è  Warnings
```
‚ö†Ô∏è  2 WARNINGS:
  - Open Z-Score mean=0.35 (devrait √™tre ~0)
  - 10% de NaN dans RSI (acceptable pour warm-up)
```
**Action:** V√©rifier manuellement, acceptable si expliqu√©.

---

## üîß D√©pannage

### Erreur: "Bougies sans 6 steps"
**Cause:** Donn√©es 5min incompl√®tes (d√©but/fin de p√©riode)
**Solution:**
- C'est normal pour les bougies en bordure
- Au moins 80% des bougies doivent √™tre compl√®tes
- Utiliser un dataset plus long si n√©cessaire

### Erreur: "Amplitude n√©gative"
**Cause:** Bug dans le calcul ou OHLC invalide
**Solution:**
- V√©rifier le calcul: `amplitude = (H - L) / O`
- V√©rifier OHLC integrity en amont

### Erreur: "Data leakage d√©tect√©"
**Cause:** Feature utilise des donn√©es futures
**Solution:**
- V√©rifier que la feature est causale
- Utiliser d√©calage temporel si n√©cessaire
- Ne PAS utiliser de donn√©es apr√®s timestamp[t]

### Erreur: "Open Z-Score mean √©loign√© de 0"
**Cause:** Dataset trop petit ou biais dans les donn√©es
**Solution:**
- Acceptable pour petits datasets (<500 bougies)
- Pour production: utiliser >5000 bougies
- V√©rifier absence de trend fort dans les donn√©es

---

## üìà M√©triques de Qualit√©

### Dataset Production
- **Lignes:** >10,000 (pour training stable)
- **Features:** 15-30 (pas trop pour √©viter overfitting)
- **Labels balance:** 45-55% (√©quilibr√©)
- **NaN:** <5% (sauf warm-up filtres)
- **Leakage:** Toutes features |corr| < 0.5
- **Corr√©lation id√©ale:** 10-20 features dans [0.1, 0.3]

### Dataset Multi-Actifs
- **Actifs:** 2-5 (BTC+ETH minimum)
- **Distribution:** 30-70% par actif (√©quilibr√©)
- **Normalisation:** PAR ACTIF (critique!)
- **P√©riode commune:** Au moins 6 mois de donn√©es

---

## üí° Bonnes Pratiques

1. **Toujours visualiser** les donn√©es avant entra√Ænement
2. **Tester sur √©chantillon** avant dataset complet
3. **Valider chaque √©tape** s√©par√©ment
4. **Sauvegarder les graphiques** pour r√©f√©rence
5. **Documenter les anomalies** dans le rapport
6. **Versionner les datasets** (btc_v1.csv, btc_v2.csv, etc.)
7. **Comparer les statistiques** entre versions

---

## üéì Pour Aller Plus Loin

### Cr√©er un Nouveau Test
```python
# tests/test_my_feature.py

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

def test_my_feature():
    """Test de ma nouvelle feature."""
    from my_module import my_function

    # Test
    result = my_function(input_data)

    # Assertions
    assert result is not None, "Result shouldn't be None"
    assert len(result) > 0, "Result shouldn't be empty"

    print("‚úÖ Test passed!")

if __name__ == '__main__':
    test_my_feature()
```

### Ajouter une Visualisation
```python
import matplotlib.pyplot as plt

def visualize_feature(df, feature_name):
    """Visualise une feature."""
    plt.figure(figsize=(12, 6))

    # Histogram
    plt.subplot(1, 2, 1)
    df[feature_name].hist(bins=50)
    plt.title(f'Distribution: {feature_name}')

    # Time series
    plt.subplot(1, 2, 2)
    plt.plot(df[feature_name])
    plt.title(f'Evolution: {feature_name}')

    plt.savefig(f'tests/validation_output/{feature_name}.png')
    plt.close()
```

---

## üìû Support

Si les tests √©chouent de mani√®re persistante:
1. Lire le rapport complet: `tests/validation_output/validation_report.txt`
2. Examiner les visualisations
3. V√©rifier les logs d√©taill√©s
4. Tester avec donn√©es synth√©tiques
5. Consulter la documentation du pipeline

---

**Derni√®re mise √† jour:** 2026-01-01
**Version tests:** 1.0
**Auteur:** Pipeline Validation Team
