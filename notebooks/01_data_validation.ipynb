{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation du Dataset - Pipeline de Données Crypto\n",
    "\n",
    "Ce notebook valide la qualité du dataset généré par le pipeline.\n",
    "\n",
    "**Vérifications:**\n",
    "1. Pas de data leakage\n",
    "2. Intégrité OHLC\n",
    "3. Distribution des labels\n",
    "4. Qualité des features normalisées\n",
    "5. Visualisation du signal filtré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset généré\n",
    "dataset_path = '../data/processed/btc_30m_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path, parse_dates=['timestamp', 'candle_30m_timestamp'])\n",
    "\n",
    "print(f\"Dataset chargé: {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "print(f\"Période: {df['timestamp'].min()} à {df['timestamp'].max()}\")\n",
    "print(f\"\\nPremières colonnes: {list(df.columns[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des données\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info sur le dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation de la Bougie Fantôme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier les steps (doivent aller de 1 à 6 pour 30min)\n",
    "print(\"Distribution des steps:\")\n",
    "print(df['step'].value_counts().sort_index())\n",
    "\n",
    "# Visualiser\n",
    "df['step'].value_counts().sort_index().plot(kind='bar', figsize=(10, 4))\n",
    "plt.title('Distribution des Steps dans les Bougies 30min')\n",
    "plt.xlabel('Step (1-6)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier l'intégrité OHLC de la bougie fantôme\n",
    "from utils import validate_ohlc_integrity\n",
    "\n",
    "try:\n",
    "    validate_ohlc_integrity(df, col_prefix='ghost_')\n",
    "    print(\"✅ Intégrité OHLC: OK\")\n",
    "except ValueError as e:\n",
    "    print(f\"❌ Erreur d'intégrité OHLC: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser une bougie fantôme en formation\n",
    "sample_candle = df[df['candle_30m_timestamp'] == df['candle_30m_timestamp'].iloc[100]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "axes[0,0].plot(sample_candle['step'], sample_candle['ghost_open'], marker='o', label='Open')\n",
    "axes[0,0].set_title('Ghost Open')\n",
    "axes[0,0].set_xlabel('Step')\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(sample_candle['step'], sample_candle['ghost_high'], marker='o', label='High', color='green')\n",
    "axes[0,1].set_title('Ghost High')\n",
    "axes[0,1].set_xlabel('Step')\n",
    "axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(sample_candle['step'], sample_candle['ghost_low'], marker='o', label='Low', color='red')\n",
    "axes[1,0].set_title('Ghost Low')\n",
    "axes[1,0].set_xlabel('Step')\n",
    "axes[1,0].legend()\n",
    "\n",
    "axes[1,1].plot(sample_candle['step'], sample_candle['ghost_close'], marker='o', label='Close', color='blue')\n",
    "axes[1,1].set_title('Ghost Close')\n",
    "axes[1,1].set_xlabel('Step')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Évolution de la Bougie Fantôme', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation des Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des labels\n",
    "print(\"Distribution des labels:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "print(f\"\\nPourcentage de labels positifs: {label_counts.get(1.0, 0) / label_counts.sum() * 100:.2f}%\")\n",
    "\n",
    "# Visualiser\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "label_counts.plot(kind='bar', ax=axes[0], color=['red', 'green'])\n",
    "axes[0].set_title('Distribution des Labels')\n",
    "axes[0].set_xlabel('Label (0=Baisse, 1=Hausse)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "label_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=['red', 'green'])\n",
    "axes[1].set_title('Proportion des Labels')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser le signal filtré et les labels\n",
    "sample = df.iloc[1000:1200].copy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Signal filtré\n",
    "if 'rsi_filtered' in sample.columns:\n",
    "    axes[0].plot(sample.index, sample['rsi_filtered'], label='RSI Filtré', color='blue')\n",
    "    axes[0].set_title('Signal Filtré (RSI avec Filtre d\\'Octave)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "# Pente\n",
    "if 'slope_shifted' in sample.columns:\n",
    "    axes[1].plot(sample.index, sample['slope_shifted'], label='Pente Décalée', color='orange')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_title('Pente du Signal Filtré (Décalée)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "# Labels\n",
    "colors = ['red' if l == 0 else 'green' for l in sample['label']]\n",
    "axes[2].scatter(sample.index, sample['label'], c=colors, alpha=0.6, s=20)\n",
    "axes[2].set_title('Labels (0=Baisse, 1=Hausse)')\n",
    "axes[2].set_xlabel('Index')\n",
    "axes[2].set_yticks([0, 1])\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vérification du Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_data_leakage\n",
    "\n",
    "# Liste des features (exclure les colonnes non-feature)\n",
    "exclude_cols = ['timestamp', 'candle_30m_timestamp', 'label', 'slope', 'slope_shifted', \n",
    "                'rsi_filtered', 'close_filtered', 'step']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"Vérification du data leakage sur {len(feature_cols)} features...\")\n",
    "\n",
    "leakage_results = check_data_leakage(df, feature_cols, label_col='label')\n",
    "\n",
    "if leakage_results['suspicious_features']:\n",
    "    print(f\"\\n❌ {len(leakage_results['suspicious_features'])} features suspectes détectées:\")\n",
    "    for feat, corr in leakage_results['suspicious_features']:\n",
    "        print(f\"  - {feat}: corrélation {corr:.3f} avec label[t+1]\")\n",
    "else:\n",
    "    print(\"\\n✅ Pas de data leakage détecté!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les corrélations futures\n",
    "future_corrs = leakage_results['future_correlation']\n",
    "\n",
    "# Trier par valeur absolue\n",
    "sorted_corrs = sorted(future_corrs.items(), key=lambda x: abs(x[1]), reverse=True)[:20]\n",
    "\n",
    "features = [x[0] for x in sorted_corrs]\n",
    "corrs = [x[1] for x in sorted_corrs]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if abs(c) > 0.7 else 'orange' if abs(c) > 0.5 else 'green' for c in corrs]\n",
    "plt.barh(features, corrs, color=colors)\n",
    "plt.axvline(x=0.7, color='red', linestyle='--', label='Seuil suspect (0.7)')\n",
    "plt.axvline(x=-0.7, color='red', linestyle='--')\n",
    "plt.xlabel('Corrélation avec label[t+1]')\n",
    "plt.title('Top 20 Features - Corrélation Future (Leakage Check)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Qualité des Features Normalisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier que les features normalisées ont mean~0 et std~1\n",
    "normalized_cols = [col for col in df.columns if '_norm' in col]\n",
    "\n",
    "print(f\"Analyse de {len(normalized_cols)} features normalisées:\\n\")\n",
    "\n",
    "stats = []\n",
    "for col in normalized_cols[:10]:  # Afficher les 10 premières\n",
    "    values = df[col].dropna()\n",
    "    stats.append({\n",
    "        'feature': col,\n",
    "        'mean': values.mean(),\n",
    "        'std': values.std(),\n",
    "        'min': values.min(),\n",
    "        'max': values.max()\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des features normalisées\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(normalized_cols[:4]):\n",
    "    df[col].dropna().hist(bins=50, ax=axes[i], edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Distribution: {col}')\n",
    "    axes[i].axvline(x=0, color='red', linestyle='--', label='Mean')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques globales\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs manquantes\n",
    "null_counts = df.isnull().sum()\n",
    "null_pct = (null_counts / len(df) * 100).round(2)\n",
    "\n",
    "null_df = pd.DataFrame({\n",
    "    'column': null_counts.index,\n",
    "    'null_count': null_counts.values,\n",
    "    'null_pct': null_pct.values\n",
    "})\n",
    "\n",
    "null_df = null_df[null_df['null_count'] > 0].sort_values('null_count', ascending=False)\n",
    "\n",
    "print(\"Colonnes avec valeurs manquantes:\")\n",
    "print(null_df.to_string(index=False))\n",
    "\n",
    "if len(null_df) == 0:\n",
    "    print(\"\\n✅ Aucune valeur manquante!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prêt pour l'Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec label=NaN\n",
    "df_clean = df.dropna(subset=['label'])\n",
    "\n",
    "print(f\"Dataset nettoyé: {len(df_clean)} lignes ({len(df_clean)/len(df)*100:.1f}% du total)\")\n",
    "print(f\"Colonnes: {len(df_clean.columns)}\")\n",
    "\n",
    "# Séparer features et label\n",
    "feature_cols_final = [col for col in df_clean.columns \n",
    "                     if col not in ['timestamp', 'candle_30m_timestamp', 'label', \n",
    "                                   'slope', 'slope_shifted', 'rsi_filtered', 'close_filtered']]\n",
    "\n",
    "X = df_clean[feature_cols_final]\n",
    "y = df_clean['label']\n",
    "\n",
    "print(f\"\\nFeatures (X): {X.shape}\")\n",
    "print(f\"Labels (y): {y.shape}\")\n",
    "print(f\"\\n✅ Dataset prêt pour l'entraînement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder une version nettoyée\n",
    "output_clean = '../data/processed/btc_30m_dataset_clean.csv'\n",
    "df_clean.to_csv(output_clean, index=False)\n",
    "print(f\"Dataset nettoyé sauvegardé: {output_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé de la Validation\n",
    "\n",
    "✅ **Checklist:**\n",
    "- [ ] Bougie fantôme correctement formée (6 steps)\n",
    "- [ ] Intégrité OHLC validée\n",
    "- [ ] Labels équilibrés (40-60%)\n",
    "- [ ] Pas de data leakage détecté\n",
    "- [ ] Features normalisées correctement\n",
    "- [ ] Dataset prêt pour entraînement\n",
    "\n",
    "**Prochaines étapes:**\n",
    "1. Créer le modèle CNN-LSTM/TCN\n",
    "2. Entraînement avec GPU\n",
    "3. Validation croisée temporelle\n",
    "4. Backtesting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
