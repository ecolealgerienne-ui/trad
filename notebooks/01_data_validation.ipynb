{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation du Dataset - Pipeline de Donn√©es Crypto\n",
    "\n",
    "Ce notebook valide la qualit√© du dataset g√©n√©r√© par le pipeline.\n",
    "\n",
    "**V√©rifications:**\n",
    "1. Pas de data leakage\n",
    "2. Int√©grit√© OHLC\n",
    "3. Distribution des labels\n",
    "4. Qualit√© des features normalis√©es\n",
    "5. Visualisation du signal filtr√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset g√©n√©r√©\n",
    "dataset_path = '../data/processed/btc_30m_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_path, parse_dates=['timestamp', 'candle_30m_timestamp'])\n",
    "\n",
    "print(f\"Dataset charg√©: {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "print(f\"P√©riode: {df['timestamp'].min()} √† {df['timestamp'].max()}\")\n",
    "print(f\"\\nPremi√®res colonnes: {list(df.columns[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu des donn√©es\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info sur le dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation de la Bougie Fant√¥me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier les steps (doivent aller de 1 √† 6 pour 30min)\n",
    "print(\"Distribution des steps:\")\n",
    "print(df['step'].value_counts().sort_index())\n",
    "\n",
    "# Visualiser\n",
    "df['step'].value_counts().sort_index().plot(kind='bar', figsize=(10, 4))\n",
    "plt.title('Distribution des Steps dans les Bougies 30min')\n",
    "plt.xlabel('Step (1-6)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier l'int√©grit√© OHLC de la bougie fant√¥me\n",
    "from utils import validate_ohlc_integrity\n",
    "\n",
    "try:\n",
    "    validate_ohlc_integrity(df, col_prefix='ghost_')\n",
    "    print(\"‚úÖ Int√©grit√© OHLC: OK\")\n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Erreur d'int√©grit√© OHLC: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser une bougie fant√¥me en formation\n",
    "sample_candle = df[df['candle_30m_timestamp'] == df['candle_30m_timestamp'].iloc[100]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "axes[0,0].plot(sample_candle['step'], sample_candle['ghost_open'], marker='o', label='Open')\n",
    "axes[0,0].set_title('Ghost Open')\n",
    "axes[0,0].set_xlabel('Step')\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(sample_candle['step'], sample_candle['ghost_high'], marker='o', label='High', color='green')\n",
    "axes[0,1].set_title('Ghost High')\n",
    "axes[0,1].set_xlabel('Step')\n",
    "axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(sample_candle['step'], sample_candle['ghost_low'], marker='o', label='Low', color='red')\n",
    "axes[1,0].set_title('Ghost Low')\n",
    "axes[1,0].set_xlabel('Step')\n",
    "axes[1,0].legend()\n",
    "\n",
    "axes[1,1].plot(sample_candle['step'], sample_candle['ghost_close'], marker='o', label='Close', color='blue')\n",
    "axes[1,1].set_title('Ghost Close')\n",
    "axes[1,1].set_xlabel('Step')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('√âvolution de la Bougie Fant√¥me', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validation des Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des labels\n",
    "print(\"Distribution des labels:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "print(f\"\\nPourcentage de labels positifs: {label_counts.get(1.0, 0) / label_counts.sum() * 100:.2f}%\")\n",
    "\n",
    "# Visualiser\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "label_counts.plot(kind='bar', ax=axes[0], color=['red', 'green'])\n",
    "axes[0].set_title('Distribution des Labels')\n",
    "axes[0].set_xlabel('Label (0=Baisse, 1=Hausse)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "label_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=['red', 'green'])\n",
    "axes[1].set_title('Proportion des Labels')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser le signal filtr√© et les labels\n",
    "sample = df.iloc[1000:1200].copy()\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Signal filtr√©\n",
    "if 'rsi_filtered' in sample.columns:\n",
    "    axes[0].plot(sample.index, sample['rsi_filtered'], label='RSI Filtr√©', color='blue')\n",
    "    axes[0].set_title('Signal Filtr√© (RSI avec Filtre d\\'Octave)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "# Pente\n",
    "if 'slope_shifted' in sample.columns:\n",
    "    axes[1].plot(sample.index, sample['slope_shifted'], label='Pente D√©cal√©e', color='orange')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_title('Pente du Signal Filtr√© (D√©cal√©e)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "# Labels\n",
    "colors = ['red' if l == 0 else 'green' for l in sample['label']]\n",
    "axes[2].scatter(sample.index, sample['label'], c=colors, alpha=0.6, s=20)\n",
    "axes[2].set_title('Labels (0=Baisse, 1=Hausse)')\n",
    "axes[2].set_xlabel('Index')\n",
    "axes[2].set_yticks([0, 1])\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. V√©rification du Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_data_leakage\n",
    "\n",
    "# Liste des features (exclure les colonnes non-feature)\n",
    "exclude_cols = ['timestamp', 'candle_30m_timestamp', 'label', 'slope', 'slope_shifted', \n",
    "                'rsi_filtered', 'close_filtered', 'step']\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"V√©rification du data leakage sur {len(feature_cols)} features...\")\n",
    "\n",
    "leakage_results = check_data_leakage(df, feature_cols, label_col='label')\n",
    "\n",
    "if leakage_results['suspicious_features']:\n",
    "    print(f\"\\n‚ùå {len(leakage_results['suspicious_features'])} features suspectes d√©tect√©es:\")\n",
    "    for feat, corr in leakage_results['suspicious_features']:\n",
    "        print(f\"  - {feat}: corr√©lation {corr:.3f} avec label[t+1]\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Pas de data leakage d√©tect√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les corr√©lations futures\n",
    "future_corrs = leakage_results['future_correlation']\n",
    "\n",
    "# Trier par valeur absolue\n",
    "sorted_corrs = sorted(future_corrs.items(), key=lambda x: abs(x[1]), reverse=True)[:20]\n",
    "\n",
    "features = [x[0] for x in sorted_corrs]\n",
    "corrs = [x[1] for x in sorted_corrs]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if abs(c) > 0.7 else 'orange' if abs(c) > 0.5 else 'green' for c in corrs]\n",
    "plt.barh(features, corrs, color=colors)\n",
    "plt.axvline(x=0.7, color='red', linestyle='--', label='Seuil suspect (0.7)')\n",
    "plt.axvline(x=-0.7, color='red', linestyle='--')\n",
    "plt.xlabel('Corr√©lation avec label[t+1]')\n",
    "plt.title('Top 20 Features - Corr√©lation Future (Leakage Check)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Qualit√© des Features Normalis√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier que les features normalis√©es ont mean~0 et std~1\n",
    "normalized_cols = [col for col in df.columns if '_norm' in col]\n",
    "\n",
    "print(f\"Analyse de {len(normalized_cols)} features normalis√©es:\\n\")\n",
    "\n",
    "stats = []\n",
    "for col in normalized_cols[:10]:  # Afficher les 10 premi√®res\n",
    "    values = df[col].dropna()\n",
    "    stats.append({\n",
    "        'feature': col,\n",
    "        'mean': values.mean(),\n",
    "        'std': values.std(),\n",
    "        'min': values.min(),\n",
    "        'max': values.max()\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "print(stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution des features normalis√©es\nfig, axes = plt.subplots(2, 2, figsize=(14, 8))\naxes = axes.flatten()\n\nfor i, col in enumerate(normalized_cols[:4]):\n    df[col].dropna().hist(bins=50, ax=axes[i], edgecolor='black', alpha=0.7)\n    axes[i].set_title(f'Distribution: {col}')\n    axes[i].axvline(x=0, color='red', linestyle='--', label='Mean')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "## 5b. Validation des Features Avanc√©es\n\n**Features ajout√©es pour >90% accuracy:**\n- Velocity features: velocity, amplitude, acceleration\n- Log returns: ghost_high_log, ghost_low_log, ghost_close_log\n- Open Z-Score: ghost_open_zscore (contexte de prix)\n- Step index normalis√©: step_index_norm (0.0-1.0)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# V√©rifier les Log Returns et Open Z-Score\nif 'ghost_high_log' in df.columns and 'ghost_low_log' in df.columns and 'ghost_close_log' in df.columns:\n    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n    \n    # Distribution des Log Returns\n    df['ghost_high_log'].dropna().hist(bins=50, ax=axes[0,0], edgecolor='black', alpha=0.7, color='green')\n    axes[0,0].set_title('Distribution: Ghost High Log Returns')\n    axes[0,0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n    \n    df['ghost_low_log'].dropna().hist(bins=50, ax=axes[0,1], edgecolor='black', alpha=0.7, color='red')\n    axes[0,1].set_title('Distribution: Ghost Low Log Returns')\n    axes[0,1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n    \n    df['ghost_close_log'].dropna().hist(bins=50, ax=axes[1,0], edgecolor='black', alpha=0.7, color='blue')\n    axes[1,0].set_title('Distribution: Ghost Close Log Returns')\n    axes[1,0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n    \n    # Open Z-Score\n    if 'ghost_open_zscore' in df.columns:\n        df['ghost_open_zscore'].dropna().hist(bins=50, ax=axes[1,1], edgecolor='black', alpha=0.7, color='purple')\n        axes[1,1].set_title('Distribution: Ghost Open Z-Score (Contexte Prix)')\n        axes[1,1].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n        axes[1,1].axvline(x=-2, color='orange', linestyle='--', alpha=0.3, label='Survente')\n        axes[1,1].axvline(x=2, color='orange', linestyle='--', alpha=0.3, label='Surachat')\n        axes[1,1].legend()\n    \n    plt.tight_layout()\n    plt.suptitle('Log Returns & Open Z-Score - Distributions', y=1.02, fontsize=14)\n    plt.show()\n    \n    # V√©rifier que les log returns sont centr√©s autour de 0\n    print(\"\\\\nüìä Statistiques des Log Returns:\")\n    for col in ['ghost_high_log', 'ghost_low_log', 'ghost_close_log']:\n        values = df[col].dropna()\n        print(f\"{col}: mean={values.mean():.6f} (should be ~0), std={values.std():.6f}\")\n    \n    if 'ghost_open_zscore' in df.columns:\n        values = df['ghost_open_zscore'].dropna()\n        print(f\"\\\\nghost_open_zscore: mean={values.mean():.6f} (should be ~0), std={values.std():.6f} (should be ~1)\")\nelse:\n    print(\"‚ö†Ô∏è  Log returns non trouv√©s dans le dataset\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualiser les Velocity Features pour une bougie √©chantillon\nsample_candle = df[df['candle_30m_timestamp'] == df['candle_30m_timestamp'].iloc[200]].copy()\n\nif 'velocity' in df.columns and 'amplitude' in df.columns:\n    fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n    \n    # Velocity\n    axes[0,0].plot(sample_candle['step'], sample_candle['velocity'], marker='o', color='purple')\n    axes[0,0].set_title('Velocity (Vitesse de Formation)')\n    axes[0,0].set_xlabel('Step')\n    axes[0,0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # Amplitude\n    axes[0,1].plot(sample_candle['step'], sample_candle['amplitude'], marker='o', color='orange')\n    axes[0,1].set_title('Amplitude (Volatilit√© Relative)')\n    axes[0,1].set_xlabel('Step')\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # Acceleration\n    if 'acceleration' in df.columns:\n        axes[1,0].plot(sample_candle['step'], sample_candle['acceleration'], marker='o', color='red')\n        axes[1,0].set_title('Acceleration (Variation entre Steps)')\n        axes[1,0].set_xlabel('Step')\n        axes[1,0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n        axes[1,0].grid(True, alpha=0.3)\n    \n    # Step Index Normalized\n    if 'step_index_norm' in df.columns:\n        axes[1,1].plot(sample_candle['step'], sample_candle['step_index_norm'], marker='o', color='blue')\n        axes[1,1].set_title('Step Index Normalis√© (0.0-1.0)')\n        axes[1,1].set_xlabel('Step')\n        axes[1,1].set_ylim(-0.1, 1.1)\n        axes[1,1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.suptitle('Features Avanc√©es - Dynamique de Formation', y=1.02, fontsize=14)\n    plt.show()\nelse:\n    print(\"‚ö†Ô∏è  Velocity features non trouv√©es dans le dataset\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# V√©rifier la pr√©sence des features avanc√©es\nadvanced_features = {\n    'Velocity': ['velocity', 'amplitude', 'acceleration'],\n    'Log Returns': ['ghost_high_log', 'ghost_low_log', 'ghost_close_log'],\n    'Open Context': ['ghost_open_zscore'],\n    'Step Normalized': ['step_index_norm']\n}\n\nprint(\"üìä V√©rification des Features Avanc√©es:\\n\")\nfor category, features in advanced_features.items():\n    print(f\"{category}:\")\n    for feat in features:\n        exists = feat in df.columns\n        symbol = \"‚úÖ\" if exists else \"‚ùå\"\n        print(f\"  {symbol} {feat}\")\n        if exists:\n            values = df[feat].dropna()\n            print(f\"      mean={values.mean():.4f}, std={values.std():.4f}, \"\n                  f\"min={values.min():.4f}, max={values.max():.4f}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques globales\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs manquantes\n",
    "null_counts = df.isnull().sum()\n",
    "null_pct = (null_counts / len(df) * 100).round(2)\n",
    "\n",
    "null_df = pd.DataFrame({\n",
    "    'column': null_counts.index,\n",
    "    'null_count': null_counts.values,\n",
    "    'null_pct': null_pct.values\n",
    "})\n",
    "\n",
    "null_df = null_df[null_df['null_count'] > 0].sort_values('null_count', ascending=False)\n",
    "\n",
    "print(\"Colonnes avec valeurs manquantes:\")\n",
    "print(null_df.to_string(index=False))\n",
    "\n",
    "if len(null_df) == 0:\n",
    "    print(\"\\n‚úÖ Aucune valeur manquante!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pr√™t pour l'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec label=NaN\n",
    "df_clean = df.dropna(subset=['label'])\n",
    "\n",
    "print(f\"Dataset nettoy√©: {len(df_clean)} lignes ({len(df_clean)/len(df)*100:.1f}% du total)\")\n",
    "print(f\"Colonnes: {len(df_clean.columns)}\")\n",
    "\n",
    "# S√©parer features et label\n",
    "feature_cols_final = [col for col in df_clean.columns \n",
    "                     if col not in ['timestamp', 'candle_30m_timestamp', 'label', \n",
    "                                   'slope', 'slope_shifted', 'rsi_filtered', 'close_filtered']]\n",
    "\n",
    "X = df_clean[feature_cols_final]\n",
    "y = df_clean['label']\n",
    "\n",
    "print(f\"\\nFeatures (X): {X.shape}\")\n",
    "print(f\"Labels (y): {y.shape}\")\n",
    "print(f\"\\n‚úÖ Dataset pr√™t pour l'entra√Ænement!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder une version nettoy√©e\n",
    "output_clean = '../data/processed/btc_30m_dataset_clean.csv'\n",
    "df_clean.to_csv(output_clean, index=False)\n",
    "print(f\"Dataset nettoy√© sauvegard√©: {output_clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© de la Validation\n",
    "\n",
    "‚úÖ **Checklist:**\n",
    "- [ ] Bougie fant√¥me correctement form√©e (6 steps)\n",
    "- [ ] Int√©grit√© OHLC valid√©e\n",
    "- [ ] Labels √©quilibr√©s (40-60%)\n",
    "- [ ] Pas de data leakage d√©tect√©\n",
    "- [ ] Features normalis√©es correctement\n",
    "- [ ] Dataset pr√™t pour entra√Ænement\n",
    "\n",
    "**Prochaines √©tapes:**\n",
    "1. Cr√©er le mod√®le CNN-LSTM/TCN\n",
    "2. Entra√Ænement avec GPU\n",
    "3. Validation crois√©e temporelle\n",
    "4. Backtesting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}